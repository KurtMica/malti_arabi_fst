{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15725,"status":"ok","timestamp":1680947155928,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"zTPm67tFHXYB","outputId":"2be2bbdb-6f14-4a4d-ab90-5440400781cc"},"outputs":[],"source":["# !git clone https://github.com/fadhleryani/malti_arabi_fst.git\n","# # !git pull\n","\n","# %pip install pynini\n","# %pip install pyfoma"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1680772861174,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"MgN2ht6q3QAH","outputId":"0a90890b-21b8-4e93-a193-3bc2306d3dc8"},"outputs":[],"source":["# %cd malti_arabi_fst"]},{"cell_type":"code","execution_count":205,"metadata":{"id":"dn2vYkczBeMZ"},"outputs":[],"source":["import pynini as pn\n","import kenlm\n","from itertools import product\n","import pyconll\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer\n","import re\n","from sklearn.feature_extraction.text import strip_accents_unicode"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/data/arabi_data/arabic_lm/aggregated_country/lm/word/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n","Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/data/arabi_data/arabic_lm/aggregated_country/lm/char/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n"]}],"source":["wordmodel = kenlm.Model('data/arabi_data/arabic_lm/aggregated_country/lm/word/tn-maghreb.arpa')\n","charmodel = kenlm.Model('data/arabi_data/arabic_lm/aggregated_country/lm/char/tn-maghreb.arpa')"]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[],"source":["def merge_conllu(dataset,charhist=False):\n","    dev = pyconll.load_from_file(f'data/malti_data/{dataset}/dev.conllu')\n","    train = pyconll.load_from_file(f'data/malti_data/{dataset}/train.conllu')\n","    test = pyconll.load_from_file(f'data/malti_data/{dataset}/test.conllu')\n","    allsets = dev._sentences + train._sentences + test._sentences\n","\n","    print(f'# of sents in {dataset}',len(allsets))\n","\n","    keys = [\"id\",\"form\",\"lemma\",\"upos\",\"xpos\",\"feats\",\"head\",\"deprel\",\"deps\",\"misc\"]\n","\n","    sents = []\n","    for sent in allsets:\n","        # toks = [pd.Series({'sent_id':sent.id,'sent':sent.text})]\n","        toks = []\n","        for tok in sent:\n","            tokdict = {'sent_id':sent.id}\n","            tokdict.update( {k:tok.__getattribute__(k) for k in keys})\n","            toks.append (pd.Series(tokdict))\n","        sents.append(pd.DataFrame(toks))\n","    df = pd.concat(sents)    \n","    # word_hist\n","    \n","    word_hist = df['form'].dropna().value_counts().reset_index()\n","    # word_hist.to_clipboard()\n","    print(f'# of words (uniq) in {dataset}',len(word_hist))\n","    # # char hist\n","    char_hist = pd.DataFrame([y for x in df['form'].dropna().str.casefold() for y in x]).value_counts()\n","    # char_hist.to_clipboard()\n","    print(f'# of chars (uniq) {dataset}',len(char_hist))\n","    return df"]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["# of sents in MLRS POS 6167\n","# of words (uniq) in MLRS POS 15774\n","# of chars (uniq) MLRS POS 81\n","# of sents in Sentiment Analysis 851\n","# of words (uniq) in Sentiment Analysis 5425\n","# of chars (uniq) Sentiment Analysis 70\n","# of sents in MAPA 8763\n","# of words (uniq) in MAPA 19059\n","# of chars (uniq) MAPA 143\n","# of sents in mt_mudt-ud 2074\n","# of words (uniq) in mt_mudt-ud 8471\n","# of chars (uniq) mt_mudt-ud 74\n"]}],"source":["mlrs = merge_conllu('MLRS POS')\n","sa = merge_conllu('Sentiment Analysis')\n","mapa = merge_conllu('MAPA')\n","mudt = merge_conllu('mt_mudt-ud')"]},{"cell_type":"code","execution_count":262,"metadata":{},"outputs":[],"source":["alldata = pd.concat([mlrs,sa,mapa,mudt])\n","# alldata = alldata['form'].dropna().value_counts().reset_index()"]},{"cell_type":"code","execution_count":263,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]}],"source":["# closedclass = pd.read_csv('mappings/closed_class_mappings.tsv',sep='\\t',header=None) # already unique \n","# closedclass = dict(closedclass.values)\n","pd.Series([' '.join(x) for x in alldata['form'].values]).str.lower().str.split().explode().value_counts().to_clipboard()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":346,"metadata":{},"outputs":[],"source":["\n","malti2arabi_2char = pn.string_file('mappings/malti2arabi_2char.map').optimize()\n","arabic2arabic = pn.string_file('mappings/arabic2arabic.map').optimize()\n","malti2arabi_1char = pn.string_file('mappings/malti2arabi_1char.map').optimize()\n","shadda = pn.string_file('mappings/shadda.map').optimize()\n","final_vowels = pn.string_file('mappings/final_vowels.map').optimize()\n","special = pn.string_file('mappings/special.map').optimize()\n","everything_else = pn.string_file('mappings/everything_else.map').optimize()\n","alif_initial = pn.string_file('mappings/alif_initial.map').optimize()\n","baby_closed_class = pn.string_file('mappings/baby_closed_class.map').optimize()\n","baby_closed_class_deterministic = pn.string_file('mappings_deterministic/baby_closed_class_deterministic.map').optimize()\n","\n","sigma_malti = pn.project(malti2arabi_1char,'input')\n","sigma_arabi = pn.project(arabic2arabic,'output') \n","\n","# SIGMA\n","sigma_in = pn.project(pn.union(malti2arabi_1char,special,arabic2arabic,final_vowels,everything_else),'input')\n","sigma = pn.project(pn.union(sigma_in,special,final_vowels,everything_else),'output').optimize()\n","# sigma = pn.union(sigma,\"-\").optimize() \n","\n","rwr_first_fsts = pn.union(\n","    malti2arabi_2char,\n","    shadda,\n","    final_vowels,\n","    alif_initial,\n",").optimize()\n","\n","rwr_first = pn.cdrewrite(rwr_first_fsts,\"\",\"\",sigma.closure())\n","\n","second_fsts = pn.union(\n","    malti2arabi_1char,\n","    arabic2arabic, \n","    special,\n","    everything_else,\n",").optimize()\n","\n","translit_fst = (rwr_first @ second_fsts.closure()).optimize()\n","\n","# deterministic\n","malti2arabi_det= pn.string_file('mappings_deterministic/malti2arabi_1char_vowels_short.map').optimize()\n","special_deterministic = pn.string_file('mappings_deterministic/special_deterministic.map').optimize()\n","\n","diacs = 'ًٌٍَُِّْ'\n","dediac_cross = pn.string_file('mappings/dediac.map')\n","dediac = pn.cdrewrite(dediac_cross,'','',sigma.closure())\n","\n","augmented_closed_class = pn.string_file('mappings/augmented_closed_class.map').optimize()\n","\n","words = pn.string_file('data/arabi_data/tn-maghreb-words.txt').optimize() @ dediac"]},{"cell_type":"code","execution_count":349,"metadata":{},"outputs":[{"data":{"text/plain":["{'word_raw': 'crap',\n"," 'word_normalized': 'crap',\n"," 'translit': ['#NA'],\n"," 'translit_stripped': ['#NA'],\n"," 'wordmodel_score': [-8.091814041137695],\n"," 'charmodel_score': [-10.07141399383545],\n"," 'capitalized': False,\n"," 'in_langmodel': [False],\n"," 'subtokens': [3],\n"," 'subtokens_lowest_ties': 1}"]},"execution_count":349,"metadata":{},"output_type":"execute_result"}],"source":["translit_and_rank_options('crap')"]},{"cell_type":"code","execution_count":314,"metadata":{},"outputs":[],"source":["# paths = get_paths((\"<BOS>mil-<EOS>\"  @ baby_closed_class @ transcriber  )),get_paths((\"<BOS>fok<EOS>\"   @ transcriber  ))\n","# paths,len(paths)"]},{"cell_type":"code","execution_count":315,"metadata":{},"outputs":[],"source":["def dediac_fst(text):\n","    text = text.replace('[','\\[').replace(']','\\]')\n","    try:\n","        return (text @ dediac).string()\n","    except:\n","        return np.nan\n","    \n","words_df= pd.read_fwf('data/arabi_data/tn-maghreb-words.txt',header=None).rename(columns={0:'words'})\n","words_df['dediac'] = pd.Series([dediac_fst(x) for x in words_df['words']])\n","\n","# words_df"]},{"cell_type":"code","execution_count":348,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_raw</th>\n","      <th>word_normalized</th>\n","      <th>freq</th>\n","      <th>translit</th>\n","      <th>det</th>\n","      <th>det_smallcc</th>\n","      <th>det_fullcc</th>\n","      <th>nondet</th>\n","      <th>nondet_smallcc</th>\n","      <th>nondet_fullcc</th>\n","      <th>translit_stripped</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>subtokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>طالعة</td>\n","      <td>-6.705869</td>\n","      <td>-6.622174</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>NaN</td>\n","      <td>تلجح</td>\n","      <td>تلجح</td>\n","      <td>تلجح</td>\n","      <td>تلجح</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تلجح</td>\n","      <td>-8.091814</td>\n","      <td>-9.504936</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>NaN</td>\n","      <td>#NA</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>#NA</td>\n","      <td>NaN</td>\n","      <td>#NA</td>\n","      <td>-8.091814</td>\n","      <td>-10.071414</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  word_raw word_normalized  freq translit   det det_smallcc det_fullcc nondet   \n","1  tielgħa         tielgħa   NaN    طالعة   NaN         NaN        NaN  طالعة  \\\n","0  tielgħa         tielgħa   NaN     تلجح  تلجح        تلجح       تلجح    NaN   \n","2  tielgħa         tielgħa   NaN      #NA   NaN         NaN        NaN    NaN   \n","\n","  nondet_smallcc nondet_fullcc translit_stripped  wordmodel_score   \n","1            NaN         طالعة             طالعة        -6.705869  \\\n","0            NaN           NaN              تلجح        -8.091814   \n","2            #NA           NaN               #NA        -8.091814   \n","\n","   charmodel_score  capitalized  in_langmodel  subtokens  \n","1        -6.622174        False          True          2  \n","0        -9.504936        False         False          2  \n","2       -10.071414        False         False          3  "]},"execution_count":348,"metadata":{},"output_type":"execute_result"}],"source":["def get_paths(fst,words_only=False):\n","    paths = list(fst.paths().items())\n","    if words_only:\n","        return [x[1] for x in paths]\n","    else:\n","        return paths\n","\n","\n","\n","def apply_translit_fst(tok,backoff_fsts=[baby_closed_class,augmented_closed_class]):\n","    tok = tok.replace('[','\\[').replace(']','\\]')\n","    tok = (f'<BOS>{tok}<EOS>')\n","    # if type=='det':\n","    #     return tok @ deterministic_transcriber @ dediac\n","    if backoff_fsts:\n","        backoff =  tok @ pn.union(*backoff_fsts).optimize() @ dediac\n","        if get_paths(backoff):\n","            return backoff\n","        else:\n","            return tok  @ translit_fst @ dediac\n","    else:\n","        return tok  @ translit_fst @ dediac\n","\n","def filter_edge_diacritics(options):\n","    return [y for y in options if y[0] not in diacs and y[-1] not in diacs]\n","\n","def translit_deterministic(lowered,backoffs=[]):\n","    lowered = lowered.replace('[','\\[').replace(']','\\]') \n","    if backoffs:\n","        backofflowered = f'<BOS>{lowered}<EOS>'\n","        backoff = backofflowered @ pn.union(*backoffs).optimize() @ dediac\n","        if len(get_paths(backoff))==1:\n","            return backoff.string()\n","        elif len(get_paths(backoff))>1:\n","            print('error: fst is NOT deterministic on:',lowered)\n","            return '#na'\n","    # default\n","    try:\n","        maptranslit = (lowered @ pn.union(malti2arabi_det,special_deterministic).closure().optimize() @ dediac).string()\n","        return maptranslit\n","    except:\n","        print('error detfst on:',lowered)\n","        return '#na'\n","            \n","\n","def translit_word(lowered_tok,backoffs): #select on merged but return unmerged\n","\n","    tok_fst = apply_translit_fst(lowered_tok,backoffs)\n","    translit_toks = get_paths(tok_fst,words_only=True) \n","    if not translit_toks:\n","        return ['#NA']\n","    try:\n","        translit_toks = filter_edge_diacritics(translit_toks) \n","    except:\n","        print('err filtering diacs',translit_toks,lowered_tok)\n","    \n","    translit_toks = [ dediac_fst(x) for x in translit_toks]  # dediacritize\n","    return translit_toks\n","    \n","\n","langmodelset =  set(words_df['dediac'])\n","\n","def count_subtokens(text, tokenizer):\n","    return tokenizer(text, add_special_tokens=False, return_length=True)[\"length\"]\n","\n","def strip_plus(x):\n","    if x == \"+\":\n","        return x\n","    else:\n","        return x.rstrip(\"+\")\n","    \n","\n","def translit_and_rank_options(word,name='translit',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class]):\n","    normalized = dediacritise_non_malti_accents(word)\n","    lowered = normalized.lower()\n","    translit_dict = {\n","        'word_raw':word,\n","        'word_normalized':word,\n","        # 'word_normalized':lowered,\n","        }\n","    \n","    if fsttype == 'det':\n","        translit = [translit_deterministic(lowered)]\n","    elif fsttype == 'non-det':\n","        translit = translit_word(lowered,backoffs)\n","    else:\n","        raise Exception('wrong fsttype')\n","\n","    translit_dict[name] = translit\n","    translit_dict['translit'] = translit # keep this, in order to merge later\n","    translit_dict['translit_stripped'] = [strip_plus(x) for x in translit]\n","    translit_dict['wordmodel_score'] = [wordmodel.score(x) for x in translit_dict['translit_stripped']]\n","    translit_dict['charmodel_score'] = [charmodel.score(' '.join(x)) for x in translit_dict['translit_stripped'] ]\n","    translit_dict['capitalized'] = word[0].isupper() # TODO: what about letter after sink as in 'L-Innu', does it matter?\n","    translit_dict['in_langmodel'] = [x in langmodelset for x in translit_dict['translit_stripped']]\n","    translit_dict['subtokens'] = count_subtokens(translit_dict['translit_stripped'], tokenizer)\n","    translit_dict['subtokens_lowest_ties'] = sum(np.array(translit_dict['subtokens']) == min(translit_dict['subtokens']))\n","\n","    return translit_dict\n","    \n","\n","word = \"t'\"\n","word = \"L-Innu\"\n","word = \"din\"\n","word = \"f'dik\"\n","word = \"d-dinja\"\n","word = \"f'dil-konferenza d-dinja\"\n","word = \"mil-dinja\" # check how many tokens it breaks into and how that affects lang model scores\n","word = \"id-\"\n","word = \"fil- linja .\"\n","word = \"m'\" \n","word = \"a\"\n","word = \"uffiċjali\"\n","word = \"il-\"\n","word = \"tielgħa\"\n","# word = \"[għandhomx\" \n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['charmodel_score'],ascending=False)\n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['wordmodel_score'],ascending=False)\n","# sorted([(wordmodel.score(x),x) for x in merged],key=lambda x: -x[0])\n","\n","\n","\n","def generate_table(word):\n","    det = translit_and_rank_options(word,name='det',fsttype='det')    \n","    det_smallcc = translit_and_rank_options(word,name='det_smallcc',fsttype='det', backoffs=[baby_closed_class_deterministic])    \n","    det_fullcc = translit_and_rank_options(word,name='det_fullcc',fsttype='det', backoffs=[baby_closed_class_deterministic,augmented_closed_class])    \n","    nondet = translit_and_rank_options(word,name='nondet',fsttype='non-det')\n","    nondet_smallcc = translit_and_rank_options(word,name='nondet_smallcc',fsttype='non-det',backoffs=[baby_closed_class])\n","    nondet_fullcc = translit_and_rank_options(word,name='nondet_fullcc',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class])\n","    det['freq'] = np.nan\n","    det_smallcc['freq'] = np.nan\n","    det_fullcc['freq'] = np.nan\n","    nondet['freq'] = np.nan\n","    nondet_smallcc['freq'] = np.nan\n","    nondet_fullcc['freq'] = np.nan\n","    \n","    return (det,det_smallcc,det_fullcc,nondet,nondet_smallcc,nondet_fullcc,)\n","   \n","det,det_smallcc,det_fullcc,nondet,nondet_smallcc,nondet_fullcc = generate_table(word)\n","det = pd.DataFrame(det)\n","det_smallcc = pd.DataFrame(det_smallcc)\n","det_fullcc = pd.DataFrame(det_fullcc)\n","nondet = pd.DataFrame(nondet)\n","nondet_smallcc = pd.DataFrame(nondet_smallcc)\n","nondet_fullcc = pd.DataFrame(nondet_fullcc)\n","\n","def merge_multiple(dfs=[det,det_smallcc,det_fullcc,nondet,nondet_smallcc,nondet_fullcc]):\n","    first = dfs[0]\n","    for df in dfs[1:]:\n","        first = first.merge(df,how='outer')\n","    \n","    return first.sort_values('wordmodel_score',ascending=False)[[\n","        'word_raw',\n","        'word_normalized',\n","        'freq',\n","        'translit',\n","        'det',\n","        'det_smallcc',\n","        'det_fullcc',\n","        'nondet',\n","        'nondet_smallcc',\n","        'nondet_fullcc',        \n","        'translit_stripped',\n","        'wordmodel_score',\n","        'charmodel_score',\n","        'capitalized',\n","        'in_langmodel',\n","        'subtokens',\n","        # 'subtokens_lowest_ties',\n","        ]]\n","\n","merged = merge_multiple()\n","merged"]},{"cell_type":"code","execution_count":317,"metadata":{},"outputs":[],"source":["# word_hist = word_hist\n","# mudtdev_translit = pd.concat(word_hist['sent'].iloc[:].apply(translit_and_rank_options).values)\n","def translit_dataset(word_hist):\n","    \n","    detlist = []\n","    det_smallcclist = []\n","    det_fullcclist = []\n","    nondetlist = []\n","    nondet_smallcclist = []\n","    nondet_fullcclist = []\n","\n","    for word,freq in word_hist.values[:]:\n","        \n","        det, det_smallcc, det_fullcc, nondet, nondet_smallcc, nondet_fullcc = generate_table(word)\n","        det['freq'] = freq\n","        det_smallcc['freq'] = freq\n","        det_fullcc['freq'] = freq\n","        nondet['freq'] = freq\n","        nondet_smallcc['freq'] = freq\n","        nondet_fullcc    ['freq'] = freq\n","        \n","        detlist.append(det)\n","        det_smallcclist.append(det_smallcc)\n","        det_fullcclist.append(det_fullcc)\n","        nondetlist.append(nondet)\n","        nondet_smallcclist.append(nondet_smallcc)\n","        nondet_fullcclist.append(nondet_fullcc)\n","        \n","    \n","    detlistdf = pd.DataFrame(detlist).explode(['translit','det','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    det_smallcclistdf = pd.DataFrame(det_smallcclist).explode(['translit','det_smallcc','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    det_fullcclistdf = pd.DataFrame(det_fullcclist).explode(['translit','det_fullcc','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    nondetlistdf = pd.DataFrame(nondetlist).explode(['translit','nondet','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    nondet_smallcclistdf = pd.DataFrame(nondet_smallcclist).explode(['translit','nondet_smallcc','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    nondet_fullcclistdf = pd.DataFrame(nondet_fullcclist).explode(['translit','nondet_fullcc','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","\n","    return merge_multiple(dfs=\n","                          [\n","detlistdf,\n","det_smallcclistdf,\n","det_fullcclistdf,\n","nondetlistdf,\n","nondet_smallcclistdf,\n","nondet_fullcclistdf,\n","                          ]\n","                          )\n","\n","    "]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["error detfst on: ’\n","error detfst on: ’\n","error detfst on: ’\n","error detfst on: ‐\n","error detfst on: ‐\n","error detfst on: ‐\n","error detfst on: “\n","error detfst on: “\n","error detfst on: “\n","error detfst on: ”\n","error detfst on: ”\n","error detfst on: ”\n","error detfst on: —\n","error detfst on: —\n","error detfst on: —\n","error detfst on: @\n","error detfst on: @\n","error detfst on: @\n","error detfst on: }\n","error detfst on: }\n","error detfst on: }\n","error detfst on: {\n","error detfst on: {\n","error detfst on: {\n","error detfst on: §\n","error detfst on: §\n","error detfst on: §\n","error detfst on: soċjeta`\n","error detfst on: soċjeta`\n","error detfst on: soċjeta`\n","error detfst on: ×\n","error detfst on: ×\n","error detfst on: ×\n","error detfst on: snipped_english_sentence\n","error detfst on: snipped_english_sentence\n","error detfst on: snipped_english_sentence\n","error detfst on: socjeta`\n","error detfst on: socjeta`\n","error detfst on: socjeta`\n","error detfst on: ­\n","error detfst on: ­\n","error detfst on: ­\n","error detfst on: proprjeta`\n","error detfst on: proprjeta`\n","error detfst on: proprjeta`\n","error detfst on: ‐\n","error detfst on: ‐\n","error detfst on: ‐\n","error detfst on: ‘\n","error detfst on: ‘\n","error detfst on: ‘\n","error detfst on: ta`\n","error detfst on: ta`\n","error detfst on: ta`\n","error detfst on: #\n","error detfst on: #\n","error detfst on: #\n","error detfst on: _\n","error detfst on: _\n","error detfst on: _\n","error detfst on: _a\n","error detfst on: _a\n","error detfst on: _a\n","error detfst on: _12_2019\n","error detfst on: _12_2019\n","error detfst on: _12_2019\n","error detfst on: nullita`\n","error detfst on: nullita`\n","error detfst on: nullita`\n","error detfst on: td_uid_2_602aacad9bf2c_rand\n","error detfst on: td_uid_2_602aacad9bf2c_rand\n","error detfst on: td_uid_2_602aacad9bf2c_rand\n","error detfst on: td_uid_3_602aacad9c387_rand\n","error detfst on: td_uid_3_602aacad9c387_rand\n","error detfst on: td_uid_3_602aacad9c387_rand\n","error detfst on: td_uid_2_6033c486c7220_rand\n","error detfst on: td_uid_2_6033c486c7220_rand\n","error detfst on: td_uid_2_6033c486c7220_rand\n","error detfst on: td_uid_3_6033c486c74ab_rand\n","error detfst on: td_uid_3_6033c486c74ab_rand\n","error detfst on: td_uid_3_6033c486c74ab_rand\n","error detfst on: cjoe`\n","error detfst on: cjoe`\n","error detfst on: cjoe`\n","error detfst on: _81_39\n","error detfst on: _81_39\n","error detfst on: _81_39\n","error detfst on: _2000_a\n","error detfst on: _2000_a\n","error detfst on: _2000_a\n","error detfst on: _82_\n","error detfst on: _82_\n","error detfst on: _82_\n","error detfst on: _745\n","error detfst on: _745\n","error detfst on: _745\n","error detfst on: _81_53\n","error detfst on: _81_53\n","error detfst on: _81_53\n","error detfst on: \n","error detfst on: \n","error detfst on: \n","error detfst on: opportunita`\n","error detfst on: opportunita`\n","error detfst on: opportunita`\n","error detfst on: _2017\n","error detfst on: _2017\n","error detfst on: _2017\n","error detfst on: cioe`\n","error detfst on: cioe`\n","error detfst on: cioe`\n","error detfst on: _2018\n","error detfst on: _2018\n","error detfst on: _2018\n","error detfst on: pero`\n","error detfst on: pero`\n","error detfst on: pero`\n","error detfst on: fl`\n","error detfst on: fl`\n","error detfst on: fl`\n","error detfst on: _90_1_a\n","error detfst on: _90_1_a\n","error detfst on: _90_1_a\n","error detfst on: jo_4_2004_a\n","error detfst on: jo_4_2004_a\n","error detfst on: jo_4_2004_a\n","error detfst on: 🍋\n","error detfst on: 🍋\n","error detfst on: 🍋\n","error detfst on: _58a\n","error detfst on: _58a\n","error detfst on: _58a\n","error detfst on: f`\n","error detfst on: f`\n","error detfst on: f`\n","error detfst on: ⁄\n","error detfst on: ⁄\n","error detfst on: ⁄\n","error detfst on: td_uid_3_60278d9c1aa2e_rand\n","error detfst on: td_uid_3_60278d9c1aa2e_rand\n","error detfst on: td_uid_3_60278d9c1aa2e_rand\n","error detfst on: td_uid_2_60278f55d9310_rand\n","error detfst on: td_uid_2_60278f55d9310_rand\n","error detfst on: td_uid_2_60278f55d9310_rand\n","error detfst on: td_uid_3_60278f55d95ba_rand\n","error detfst on: td_uid_3_60278f55d95ba_rand\n","error detfst on: td_uid_3_60278f55d95ba_rand\n","error detfst on: td_uid_2_60278d9c1a5e4_rand\n","error detfst on: td_uid_2_60278d9c1a5e4_rand\n","error detfst on: td_uid_2_60278d9c1a5e4_rand\n","error detfst on: awtorita`\n","error detfst on: awtorita`\n","error detfst on: awtorita`\n","error detfst on: konformita`\n","error detfst on: konformita`\n","error detfst on: konformita`\n","error detfst on: eventwalita`\n","error detfst on: eventwalita`\n","error detfst on: eventwalita`\n","error detfst on: diffikulta`\n","error detfst on: diffikulta`\n","error detfst on: diffikulta`\n","error detfst on: td_uid_3_602a16af09058_rand\n","error detfst on: td_uid_3_602a16af09058_rand\n","error detfst on: td_uid_3_602a16af09058_rand\n","error detfst on: td_uid_2_6028c712799d4_rand\n","error detfst on: td_uid_2_6028c712799d4_rand\n","error detfst on: td_uid_2_6028c712799d4_rand\n","error detfst on: td_uid_3_6028c71279c6c_rand\n","error detfst on: td_uid_3_6028c71279c6c_rand\n","error detfst on: td_uid_3_6028c71279c6c_rand\n","error detfst on: td_uid_2_602a16af08ba8_rand\n","error detfst on: td_uid_2_602a16af08ba8_rand\n","error detfst on: td_uid_2_602a16af08ba8_rand\n","error detfst on: td_uid_2_60278e645375e_rand\n","error detfst on: td_uid_2_60278e645375e_rand\n","error detfst on: td_uid_2_60278e645375e_rand\n","error detfst on: td_uid_3_6027909e6a313_rand\n","error detfst on: td_uid_3_6027909e6a313_rand\n","error detfst on: td_uid_3_6027909e6a313_rand\n","error detfst on: td_uid_3_602ce68850492_rand\n","error detfst on: td_uid_3_602ce68850492_rand\n","error detfst on: td_uid_3_602ce68850492_rand\n","error detfst on: td_uid_3_60278f1823f85_rand\n","error detfst on: td_uid_3_60278f1823f85_rand\n","error detfst on: td_uid_3_60278f1823f85_rand\n","error detfst on: td_uid_3_60278e6453a3d_rand\n","error detfst on: td_uid_3_60278e6453a3d_rand\n","error detfst on: td_uid_3_60278e6453a3d_rand\n","error detfst on: relatatiˮ\n","error detfst on: relatatiˮ\n","error detfst on: relatatiˮ\n","error detfst on: _2019\n","error detfst on: _2019\n","error detfst on: _2019\n","error detfst on: pero`\n","error detfst on: pero`\n","error detfst on: pero`\n","error detfst on: invjolabbilita`\n","error detfst on: invjolabbilita`\n","error detfst on: invjolabbilita`\n","error detfst on: \\rin\\[\n","error detfst on: \\rin\\[\n","error detfst on: \\rin\\[\n","error detfst on: _82_16\n","error detfst on: _82_16\n","error detfst on: _82_16\n","error detfst on: _557\n","error detfst on: _557\n","error detfst on: _557\n","error detfst on: _413\n","error detfst on: _413\n","error detfst on: _413\n","error detfst on: jo_5_2008\n","error detfst on: jo_5_2008\n","error detfst on: jo_5_2008\n","error detfst on: _93\n","error detfst on: _93\n","error detfst on: _93\n","error detfst on: ©\n","error detfst on: ©\n","error detfst on: ©\n","error detfst on: jo_80_2007\n","error detfst on: jo_80_2007\n","error detfst on: jo_80_2007\n","error detfst on: sigurta`\n","error detfst on: sigurta`\n","error detfst on: sigurta`\n","error detfst on: appellabilita`\n","error detfst on: appellabilita`\n","error detfst on: appellabilita`\n","error detfst on: jo_41_2008\n","error detfst on: jo_41_2008\n","error detfst on: jo_41_2008\n","error detfst on: jo_28_2008\n","error detfst on: jo_28_2008\n","error detfst on: jo_28_2008\n","error detfst on: wara\n","error detfst on: wara\n","error detfst on: wara\n","error detfst on: f'\n","error detfst on: f'\n","error detfst on: f'\n","error detfst on: l-\n","error detfst on: l-\n","error detfst on: l-\n","error detfst on: td_youtube_player\n","error detfst on: td_youtube_player\n","error detfst on: td_youtube_player\n","error detfst on: iframe_api\n","error detfst on: iframe_api\n","error detfst on: iframe_api\n","error detfst on: øe\n","error detfst on: øe\n","error detfst on: øe\n","error detfst on: complaints_disputes\n","error detfst on: complaints_disputes\n","error detfst on: complaints_disputes\n","error detfst on: weiß\n","error detfst on: weiß\n","error detfst on: weiß\n","error detfst on: οτι\n","error detfst on: οτι\n","error detfst on: οτι\n","error detfst on: μεν\n","error detfst on: μεν\n","error detfst on: μεν\n","error detfst on: ουν\n","error detfst on: ουν\n","error detfst on: ουν\n","error detfst on: τω\n","error detfst on: τω\n","error detfst on: τω\n","error detfst on: νομοθετη\n","error detfst on: νομοθετη\n","error detfst on: νομοθετη\n","error detfst on: μαλιστα\n","error detfst on: μαλιστα\n","error detfst on: μαλιστα\n","error detfst on: πραγματευτεον\n","error detfst on: πραγματευτεον\n","error detfst on: πραγματευτεον\n","error detfst on: περι\n","error detfst on: περι\n","error detfst on: περι\n","error detfst on: την\n","error detfst on: την\n","error detfst on: την\n","error detfst on: των\n","error detfst on: των\n","error detfst on: των\n","error detfst on: νεων\n","error detfst on: νεων\n","error detfst on: νεων\n","error detfst on: παιδειαν\n","error detfst on: παιδειαν\n","error detfst on: παιδειαν\n","error detfst on: ουδεις\n","error detfst on: ουδεις\n","error detfst on: ουδεις\n","error detfst on: αν\n","error detfst on: αν\n","error detfst on: αν\n","error detfst on: αμφισβητησειε\n","error detfst on: αμφισβητησειε\n","error detfst on: αμφισβητησειε\n","error detfst on: τις\n","error detfst on: τις\n","error detfst on: τις\n","error detfst on: δ\n","error detfst on: δ\n","error detfst on: δ\n","error detfst on: εσται\n","error detfst on: εσται\n","error detfst on: εσται\n","error detfst on: η\n","error detfst on: η\n","error detfst on: η\n","error detfst on: παιδεια\n","error detfst on: παιδεια\n","error detfst on: παιδεια\n","error detfst on: δει\n","error detfst on: δει\n","error detfst on: δει\n","error detfst on: μη\n","error detfst on: μη\n","error detfst on: μη\n","error detfst on: λανθανειν\n","error detfst on: λανθανειν\n","error detfst on: λανθανειν\n","error detfst on: œuvre\n","error detfst on: œuvre\n","error detfst on: œuvre\n","error detfst on: relattivita`\n","error detfst on: relattivita`\n","error detfst on: relattivita`\n","error detfst on: ineffettivita`\n","error detfst on: ineffettivita`\n","error detfst on: ineffettivita`\n","error detfst on: _10_2019\n","error detfst on: _10_2019\n","error detfst on: _10_2019\n","error detfst on: ġja`\n","error detfst on: ġja`\n","error detfst on: ġja`\n","error detfst on: sinifikantiˮ\n","error detfst on: sinifikantiˮ\n","error detfst on: sinifikantiˮ\n","error detfst on: _11_2019\n","error detfst on: _11_2019\n","error detfst on: _11_2019\n","error detfst on: >\n","error detfst on: >\n","error detfst on: >\n","error detfst on: jo_32_2007\n","error detfst on: jo_32_2007\n","error detfst on: jo_32_2007\n","error detfst on: _87_3\n","error detfst on: _87_3\n","error detfst on: _87_3\n","error detfst on: news_\n","error detfst on: news_\n","error detfst on: news_\n","error detfst on: raba`\n","error detfst on: raba`\n","error detfst on: raba`\n","error detfst on: practitioner`\n","error detfst on: practitioner`\n","error detfst on: practitioner`\n","error detfst on: court`\n","error detfst on: court`\n","error detfst on: court`\n","error detfst on: doesn`\n","error detfst on: doesn`\n","error detfst on: doesn`\n","error detfst on: _02_2020\n","error detfst on: _02_2020\n","error detfst on: _02_2020\n","error detfst on: _2020\n","error detfst on: _2020\n","error detfst on: _2020\n","error detfst on: diġa`\n","error detfst on: diġa`\n","error detfst on: diġa`\n","error detfst on: sena`\n","error detfst on: sena`\n","error detfst on: sena`\n","error detfst on: hames`\n","error detfst on: hames`\n","error detfst on: hames`\n","error detfst on: sejjer\n","error detfst on: sejjer\n","error detfst on: sejjer\n","error detfst on: pl_malta\n","error detfst on: pl_malta\n","error detfst on: pl_malta\n","error detfst on: josephmuscat_jm\n","error detfst on: josephmuscat_jm\n","error detfst on: josephmuscat_jm\n","error detfst on: la\n","error detfst on: la\n","error detfst on: la\n","error detfst on: jo_9_2008\n","error detfst on: jo_9_2008\n","error detfst on: jo_9_2008\n","error detfst on: _517\n","error detfst on: _517\n","error detfst on: _517\n","error detfst on: _326\n","error detfst on: _326\n","error detfst on: _326\n","error detfst on: _81_2_\n","error detfst on: _81_2_\n","error detfst on: _81_2_\n","error detfst on: _140\n","error detfst on: _140\n","error detfst on: _140\n","error detfst on: bi\n","error detfst on: bi\n","error detfst on: bi\n","error detfst on: tal-\n","error detfst on: tal-\n","error detfst on: tal-\n","error detfst on: għal\n","error detfst on: għal\n","error detfst on: għal\n","error detfst on: identita`\n","error detfst on: identita`\n","error detfst on: identita`\n","error detfst on: _383\n","error detfst on: _383\n","error detfst on: _383\n","error detfst on: _264_1\n","error detfst on: _264_1\n","error detfst on: _264_1\n","error detfst on: _198_1\n","error detfst on: _198_1\n","error detfst on: _198_1\n","error detfst on: _384_1\n","error detfst on: _384_1\n","error detfst on: _384_1\n","error detfst on: _259\n","error detfst on: _259\n","error detfst on: _259\n","error detfst on: żgur\n","error detfst on: żgur\n","error detfst on: żgur\n","error detfst on: prudenza\n","error detfst on: prudenza\n","error detfst on: prudenza\n"]},{"data":{"text/plain":["('alldata', 1878763, 1878763, 59.738092209856916)"]},"execution_count":168,"metadata":{},"output_type":"execute_result"}],"source":["# mudt_translit = translit_dataset(mudt)\n","\n","# mapa_translit = translit_dataset(mapa)\n","\n","# mlrs_translit = translit_dataset(mlrs)\n","\n","# sa_translit = translit_dataset(sa)\n","\n","\n","# 'mudt',len(mudt_translit),len(mudt_translit),len(mudt_translit)/len(mudt_translit['word_raw'].unique())\n","# 'mapa',len(mapa_translit),len(mapa_translit),len(mapa_translit)/len(mapa_translit['word_raw'].unique())\n","# 'mlrs',len(mlrs_translit),len(mlrs_translit),len(mlrs_translit)/len(mlrs_translit['word_raw'].unique())\n","# 'sa',len(sa_translit),len(sa_translit),len(sa_translit)/len(sa_translit['word_raw'].unique())\n","\n","alldata_translit = translit_dataset(alldata)\n","'alldata',len(alldata_translit),len(alldata_translit),len(alldata_translit)/len(alldata_translit['word_raw'].unique())"]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[],"source":["alldata_translit.drop_duplicates(['word_raw','translit']).replace(np.nan,'<nan>').to_csv('transliterations/all_transliterated_tuples.tsv',sep='\\t',index=False)"]},{"cell_type":"code","execution_count":290,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["translit_deterministic\n","جدد\n","\n","translit_non-deterministic\n","جددا\n","جددة\n","جدده\n","جددى\n","جدذا\n","جدذة\n","جدذه\n","جدذى\n","جدضا\n","جدضة\n","جدضه\n","جدضى\n","جديدا\n","جديدة\n","جديده\n","جديدى\n","جديذا\n","جديذة\n","جديذه\n","جديذى\n","جديضا\n","جديضة\n","جديضه\n","جديضى\n","جذدا\n","جذدة\n","جذده\n","جذدى\n","جذذا\n","جذذة\n","جذذه\n","جذذى\n","جذضا\n","جذضة\n","جذضه\n","جذضى\n","جذيدا\n","جذيدة\n","جذيده\n","جذيدى\n","جذيذا\n","جذيذة\n","جذيذه\n","جذيذى\n","جذيضا\n","جذيضة\n","جذيضه\n","جذيضى\n","جضدا\n","جضدة\n","جضده\n","جضدى\n","جضذا\n","جضذة\n","جضذه\n","جضذى\n","جضضا\n","جضضة\n","جضضه\n","جضضى\n","جضيدا\n","جضيدة\n","جضيده\n","جضيدى\n","جضيذا\n","جضيذة\n","جضيذه\n","جضيذى\n","جضيضا\n","جضيضة\n","جضيضه\n","جضيضى\n"]}],"source":["test = '-'\n","test = 'PL_Malta'\n","test = 'PL_Malta'\n","test = 'by-election'\n","test = 'play-offs'\n","test = 'care-takers'\n","test = 'care'\n","test = 'psiko-analiżi'\n","test = '14-il'\n","test = 'mail'\n","test = 'e-'\n","test = 'il-'\n","test = 'e-mail'\n","test = 'ġdida'\n","\n","\n","print('translit_deterministic')\n","print(translit_deterministic(test,backoffs=[baby_closed_class,augmented_closed_class]))\n","print()\n","print('translit_non-deterministic')\n","for i in translit_word(test,backoffs=[baby_closed_class,augmented_closed_class]):\n","    print(i)"]},{"cell_type":"code","execution_count":331,"metadata":{},"outputs":[{"data":{"text/plain":["['#NA']"]},"execution_count":331,"metadata":{},"output_type":"execute_result"}],"source":["translit_word('crap',backoffs=[])"]},{"cell_type":"code","execution_count":326,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_raw</th>\n","      <th>word_normalized</th>\n","      <th>translit</th>\n","      <th>translit_stripped</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>subtokens</th>\n","      <th>subtokens_lowest_ties</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>alif</td>\n","      <td>alif</td>\n","      <td>#NA</td>\n","      <td>#NA</td>\n","      <td>-8.091814</td>\n","      <td>-10.071414</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  word_raw word_normalized translit translit_stripped  wordmodel_score   \n","0     alif            alif      #NA               #NA        -8.091814  \\\n","\n","   charmodel_score  capitalized  in_langmodel  subtokens   \n","0       -10.071414        False         False          3  \\\n","\n","   subtokens_lowest_ties  \n","0                      1  "]},"execution_count":326,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(translit_and_rank_options('alif',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class])).sort_values('wordmodel_score',ascending=False)"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_raw</th>\n","      <th>word_normalized</th>\n","      <th>freq</th>\n","      <th>translit</th>\n","      <th>det</th>\n","      <th>det_smallcc</th>\n","      <th>det_fullcc</th>\n","      <th>nondet</th>\n","      <th>nondet_smallcc</th>\n","      <th>nondet_fullcc</th>\n","      <th>translit_stripped</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>subtokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>iii</td>\n","      <td>iii</td>\n","      <td>27</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>-2.061620</td>\n","      <td>-4.263644</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>᾽</td>\n","      <td>᾽</td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>-2.061620</td>\n","      <td>-4.263644</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>OOO</td>\n","      <td>OOO</td>\n","      <td>1</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>-2.061620</td>\n","      <td>-4.263644</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>UE</td>\n","      <td>UE</td>\n","      <td>337</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>-2.061620</td>\n","      <td>-4.263644</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ai</td>\n","      <td>ai</td>\n","      <td>35</td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td></td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>-2.061620</td>\n","      <td>-4.263644</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1878758</th>\n","      <td>ġaladarba</td>\n","      <td>ġaladarba</td>\n","      <td>3</td>\n","      <td>جا لاداربا</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>جا لاداربا</td>\n","      <td>NaN</td>\n","      <td>جا لاداربا</td>\n","      <td>جا لاداربا</td>\n","      <td>-11.599415</td>\n","      <td>-15.974298</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1878759</th>\n","      <td>Ġaladarba</td>\n","      <td>Ġaladarba</td>\n","      <td>2</td>\n","      <td>جا لاداربا</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>جا لاداربا</td>\n","      <td>NaN</td>\n","      <td>جا لاداربا</td>\n","      <td>جا لاداربا</td>\n","      <td>-11.599415</td>\n","      <td>-15.974298</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1878760</th>\n","      <td>talanqas</td>\n","      <td>talanqas</td>\n","      <td>1</td>\n","      <td>تاع الانقص</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تاع الانقص</td>\n","      <td>NaN</td>\n","      <td>تاع الانقص</td>\n","      <td>تاع الانقص</td>\n","      <td>-12.839350</td>\n","      <td>-16.684526</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1878761</th>\n","      <td>bħallikieku</td>\n","      <td>bħallikieku</td>\n","      <td>22</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>NaN</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>-16.675682</td>\n","      <td>-23.698778</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1878762</th>\n","      <td>Bħallikieku</td>\n","      <td>Bħallikieku</td>\n","      <td>1</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>NaN</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>بحال اللي كيكو</td>\n","      <td>-16.675682</td>\n","      <td>-23.698778</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1878763 rows × 16 columns</p>\n","</div>"],"text/plain":["            word_raw word_normalized  freq        translit  det det_smallcc   \n","0                iii             iii    27                                   \\\n","1                  ᾽               ᾽     1                                    \n","2                OOO             OOO     1                                    \n","3                 UE              UE   337                                    \n","4                 ai              ai    35                                    \n","...              ...             ...   ...             ...  ...         ...   \n","1878758    ġaladarba       ġaladarba     3      جا لاداربا  NaN         NaN   \n","1878759    Ġaladarba       Ġaladarba     2      جا لاداربا  NaN         NaN   \n","1878760     talanqas        talanqas     1      تاع الانقص  NaN         NaN   \n","1878761  bħallikieku     bħallikieku    22  بحال اللي كيكو  NaN         NaN   \n","1878762  Bħallikieku     Bħallikieku     1  بحال اللي كيكو  NaN         NaN   \n","\n","        det_fullcc          nondet nondet_smallcc   nondet_fullcc   \n","0                              NaN            NaN             NaN  \\\n","1                                                                   \n","2                              NaN            NaN             NaN   \n","3                              NaN            NaN             NaN   \n","4                              NaN            NaN             NaN   \n","...            ...             ...            ...             ...   \n","1878758        NaN      جا لاداربا            NaN      جا لاداربا   \n","1878759        NaN      جا لاداربا            NaN      جا لاداربا   \n","1878760        NaN      تاع الانقص            NaN      تاع الانقص   \n","1878761        NaN  بحال اللي كيكو            NaN  بحال اللي كيكو   \n","1878762        NaN  بحال اللي كيكو            NaN  بحال اللي كيكو   \n","\n","        translit_stripped  wordmodel_score  charmodel_score  capitalized   \n","0                                -2.061620        -4.263644        False  \\\n","1                                -2.061620        -4.263644        False   \n","2                                -2.061620        -4.263644         True   \n","3                                -2.061620        -4.263644         True   \n","4                                -2.061620        -4.263644        False   \n","...                   ...              ...              ...          ...   \n","1878758        جا لاداربا       -11.599415       -15.974298        False   \n","1878759        جا لاداربا       -11.599415       -15.974298         True   \n","1878760        تاع الانقص       -12.839350       -16.684526        False   \n","1878761    بحال اللي كيكو       -16.675682       -23.698778        False   \n","1878762    بحال اللي كيكو       -16.675682       -23.698778         True   \n","\n","         in_langmodel  subtokens  \n","0                True          0  \n","1               False          0  \n","2                True          0  \n","3                True          0  \n","4                True          0  \n","...               ...        ...  \n","1878758         False          4  \n","1878759         False          4  \n","1878760         False          4  \n","1878761         False          4  \n","1878762         False          4  \n","\n","[1878763 rows x 16 columns]"]},"execution_count":190,"metadata":{},"output_type":"execute_result"}],"source":["# pd.read_csv('transliterations/all_transliterated_tuples.tsv',sep='\\t')\n","pd.read_csv('transliterations/all_transliterated_tuples.tsv',sep='\\t').replace(np.nan,'').replace('<nan>',np.nan)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mudt_translit.to_csv('transliterations/mudt_transliterated_tuples.tsv',sep='\\t',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mudt_translit.to_csv('transliterations/mudt_transliterated_tuples.tsv',sep='\\t',index=False,nan)\n","mapa_translit.to_csv('transliterations/mapa_transliterated_tuples.tsv',sep='\\t',index=False)\n","mlrs_translit.to_csv('transliterations/mlrs_transliterated_tuples.tsv',sep='\\t',index=False)\n","sa_translit.to_csv('transliterations/sa_transliterated_tuples.tsv',sep='\\t',index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"maltifst","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
