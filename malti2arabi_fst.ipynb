{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15725,"status":"ok","timestamp":1680947155928,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"zTPm67tFHXYB","outputId":"2be2bbdb-6f14-4a4d-ab90-5440400781cc"},"outputs":[],"source":["# !git clone https://github.com/fadhleryani/malti_arabi_fst.git\n","# # !git pull\n","\n","# %pip install pynini\n","# %pip install pyfoma"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1680772861174,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"MgN2ht6q3QAH","outputId":"0a90890b-21b8-4e93-a193-3bc2306d3dc8"},"outputs":[],"source":["# %cd malti_arabi_fst"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dn2vYkczBeMZ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/Caskroom/miniconda/base/envs/maltifst/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pynini as pn\n","import kenlm\n","from itertools import product\n","import pyconll\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/data/arabi_data/arabic_lm/aggregated_country/lm/word/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n","Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/data/arabi_data/arabic_lm/aggregated_country/lm/char/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n"]}],"source":["wordmodel = kenlm.Model('data/arabi_data/arabic_lm/aggregated_country/lm/word/tn-maghreb.arpa')\n","charmodel = kenlm.Model('data/arabi_data/arabic_lm/aggregated_country/lm/char/tn-maghreb.arpa')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["def merge_conllu(dataset,charhist=False):\n","    dev = pyconll.load_from_file(f'data/malti_data/{dataset}/dev.conllu')\n","    train = pyconll.load_from_file(f'data/malti_data/{dataset}/train.conllu')\n","    test = pyconll.load_from_file(f'data/malti_data/{dataset}/test.conllu')\n","    allsets = dev._sentences + train._sentences + test._sentences\n","\n","    print(f'# of sents in {dataset}',len(allsets))\n","\n","    keys = [\"id\",\"form\",\"lemma\",\"upos\",\"xpos\",\"feats\",\"head\",\"deprel\",\"deps\",\"misc\"]\n","\n","    sents = []\n","    for sent in allsets:\n","        # toks = [pd.Series({'sent_id':sent.id,'sent':sent.text})]\n","        toks = []\n","        for tok in sent:\n","            tokdict = {'sent_id':sent.id}\n","            tokdict.update( {k:tok.__getattribute__(k) for k in keys})\n","            toks.append (pd.Series(tokdict))\n","        sents.append(pd.DataFrame(toks))\n","    df = pd.concat(sents)    \n","    # word_hist\n","    word_hist = df['form'].dropna().value_counts().reset_index()\n","    # word_hist.to_clipboard()\n","    print(f'# of words in {dataset}',len(word_hist))\n","    # # char hist\n","    char_hist = pd.DataFrame([y for x in df['form'].dropna().str.casefold() for y in x]).value_counts()\n","    # char_hist.to_clipboard()\n","    print(f'# of chars {dataset}',len(char_hist))\n","    return word_hist"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["# of sents in MLRS POS 6167\n","# of words in MLRS POS 15774\n","# of chars MLRS POS 81\n","# of sents in Sentiment Analysis 851\n","# of words in Sentiment Analysis 5425\n","# of chars Sentiment Analysis 70\n","# of sents in MAPA 8763\n","# of words in MAPA 19059\n","# of chars MAPA 143\n","# of sents in mt_mudt-ud 2074\n","# of words in mt_mudt-ud 8471\n","# of chars mt_mudt-ud 74\n"]}],"source":["mlrs = merge_conllu('MLRS POS')\n","sa = merge_conllu('Sentiment Analysis')\n","mapa = merge_conllu('MAPA')\n","mudt = merge_conllu('mt_mudt-ud')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["closedclass = pd.read_csv('mappings/closed_class_mappings.tsv',sep='\\t',header=None) # already unique \n","closedclass = dict(closedclass.values)\n","\n"]},{"cell_type":"code","execution_count":190,"metadata":{},"outputs":[],"source":["\n","malti2arabi_2char = pn.string_file('mappings/malti2arabi_2char.map').optimize()\n","arabic2arabic = pn.string_file('mappings/arabic2arabic.map').optimize()\n","malti2arabi_1char = pn.string_file('mappings/malti2arabi_1char.map').optimize()\n","shadda = pn.string_file('mappings/shadda.map').optimize()\n","final_vowels = pn.string_file('mappings/final_vowels.map').optimize()\n","special = pn.string_file('mappings/special.map').optimize()\n","alif_initial = pn.string_file('mappings/alif_initial.map').optimize()\n","baby_closed_class = pn.string_file('mappings/baby_closed_class.map').optimize()\n","\n","sigma_malti = pn.project(malti2arabi_1char,'input')\n","sigma_arabi = pn.project(arabic2arabic,'output') \n","\n","# SIGMA\n","sigma_in = pn.project(pn.union(malti2arabi_1char,special,arabic2arabic,final_vowels),'input')\n","sigma = pn.project(pn.union(sigma_in,special,final_vowels),'output')\n","sigma = pn.union(sigma,\"-\").optimize() \n","\n","rwr_first_fsts = pn.union(\n","    malti2arabi_2char,\n","    shadda,\n","    final_vowels,\n","    alif_initial,\n",").optimize()\n","\n","rwr_first = pn.cdrewrite(rwr_first_fsts,\"\",\"\",sigma.closure())\n","\n","second_fsts = pn.union(\n","    malti2arabi_1char,\n","    arabic2arabic, \n","    special,\n",").optimize()\n","\n","translit_fst = rwr_first @ second_fsts.closure()\n","\n","malti2arabi_det= pn.string_file('mappings_deterministic/malti2arabi_1char_vowels_short.map').optimize()\n","\n","diacs = 'ًٌٍَُِّْ'\n","dediac_cross = pn.string_file('mappings/dediac.map')\n","dediac = pn.cdrewrite(dediac_cross,'','',sigma.closure())\n","\n","augmented_closed_class = pn.string_file('mappings/augmented_closed_class.map').optimize()\n","\n","words = pn.string_file('tn-maghreb-words.txt').optimize() @ dediac"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# paths = get_paths((\"<BOS>mil-<EOS>\"  @ baby_closed_class @ transcriber  )),get_paths((\"<BOS>fok<EOS>\"   @ transcriber  ))\n","# paths,len(paths)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def dediac_fst(text):\n","    text = text.replace('[','\\[').replace(']','\\]')\n","    try:\n","        return (text @ dediac).string()\n","    except:\n","        return np.nan\n","    \n","words_df= pd.read_fwf('tn-maghreb-words.txt',header=None).rename(columns={0:'words'})\n","words_df['dediac'] = pd.Series([dediac_fst(x) for x in words_df['words']])\n","\n","# words_df"]},{"cell_type":"code","execution_count":243,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>translit</th>\n","      <th>deterministic</th>\n","      <th>small_cc</th>\n","      <th>augmented_cc</th>\n","      <th>translit_stripped</th>\n","      <th>word_raw</th>\n","      <th>word_lowered</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>subtokens</th>\n","      <th>subtokens_lowest_ties</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>ال+</td>\n","      <td>NaN</td>\n","      <td>ال+</td>\n","      <td>ال+</td>\n","      <td>ال</td>\n","      <td>il-</td>\n","      <td>il-</td>\n","      <td>-4.779278</td>\n","      <td>-4.863126</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>ل+</td>\n","      <td>ل+</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ل</td>\n","      <td>il-</td>\n","      <td>il-</td>\n","      <td>-5.295598</td>\n","      <td>-4.732144</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  translit deterministic small_cc augmented_cc translit_stripped word_raw   \n","1      ال+           NaN      ال+          ال+                ال      il-  \\\n","0       ل+            ل+      NaN          NaN                 ل      il-   \n","\n","  word_lowered  wordmodel_score  charmodel_score  capitalized  in_langmodel   \n","1          il-        -4.779278        -4.863126        False          True  \\\n","0          il-        -5.295598        -4.732144        False          True   \n","\n","   subtokens  subtokens_lowest_ties  \n","1          2                      1  \n","0          1                      1  "]},"execution_count":243,"metadata":{},"output_type":"execute_result"}],"source":["def get_paths(fst,words_only=False):\n","    paths = list(fst.paths().items())\n","    if words_only:\n","        return [x[1] for x in paths]\n","    else:\n","        return paths\n","\n","\n","\n","def apply_translit_fst(tok,backoff_fsts=[baby_closed_class,augmented_closed_class]):\n","    tok = tok.replace('[','\\[').replace(']','\\]')\n","    tok = (f'<BOS>{tok}<EOS>')\n","    # if type=='det':\n","    #     return tok @ deterministic_transcriber @ dediac\n","    if backoff_fsts:\n","        backoff =  tok @ pn.union(*backoff_fsts).optimize() @ dediac\n","        if get_paths(backoff):\n","            return backoff\n","        else:\n","            return tok  @ translit_fst @ dediac\n","    else:\n","        return tok  @ translit_fst @ dediac\n","\n","def filter_edge_diacritics(options):\n","    return [y for y in options if y[0] not in diacs and y[-1] not in diacs]\n","\n","def translit_deterministic(lowered):\n","    lowered = lowered.replace('[','\\[').replace(']','\\]')\n","    try:\n","        return (lowered @ pn.union(malti2arabi_det,special).closure().optimize() @ dediac).string()\n","    except:\n","        print('deterministic fst error on:',lowered)\n","        return '#na'\n","\n","def translit_word(lowered_tok,backoffs): #select on merged but return unmerged\n","\n","    tok_fst = apply_translit_fst(lowered_tok,backoffs)\n","    translit_toks = get_paths(tok_fst,words_only=True) \n","    if not translit_toks:\n","        return ['#NA']\n","    try:\n","        translit_toks = filter_edge_diacritics(translit_toks) \n","    except:\n","        print('err filtering diacs',translit_toks,lowered_tok)\n","    \n","    translit_toks = [ dediac_fst(x) for x in translit_toks]  # dediacritize\n","    return translit_toks\n","    \n","\n","langmodelset =  set(words_df['dediac'])\n","\n","def count_subtokens(text, tokenizer):\n","    text = [x.rstrip('+') for x in text]\n","    return tokenizer(text, add_special_tokens=False, return_length=True)[\"length\"]\n","\n","\n","def translit_and_rank_options(word,name='translit',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class]):\n","  \n","    lowered = word.lower()\n","    translit_dict = {\n","        'word_raw':word,\n","        'word_lowered':lowered,\n","        }\n","    \n","    if fsttype == 'det':\n","        translit = [translit_deterministic(lowered)]\n","    elif fsttype == 'non-det':\n","        translit = translit_word(lowered,backoffs)\n","    else:\n","        raise Exception('wrong fsttype')\n","\n","    translit_dict[name] = translit\n","    translit_dict['translit'] = translit # keep this, in order to merge later\n","    translit_dict['translit_stripped'] = [x.rstrip('+') for x in translit_dict[name]]\n","    translit_dict['wordmodel_score'] = [wordmodel.score(x) for x in translit_dict['translit_stripped']]\n","    translit_dict['charmodel_score'] = [charmodel.score(' '.join(x)) for x in translit_dict['translit_stripped'] ]\n","    translit_dict['capitalized'] = word[0].isupper() # TODO: what about letter after sink as in 'L-Innu', does it matter?\n","    translit_dict['in_langmodel'] = [x in langmodelset for x in translit_dict['translit_stripped']]\n","    translit_dict['subtokens'] = count_subtokens(translit_dict['translit_stripped'], tokenizer)\n","    translit_dict['subtokens_lowest_ties'] = sum(np.array(translit_dict['subtokens']) == max(translit_dict['subtokens']))\n","\n","    return translit_dict\n","    \n","\n","word = \"t'\"\n","word = \"L-Innu\"\n","word = \"din\"\n","word = \"f'dik\"\n","word = \"d-dinja\"\n","word = \"f'dil-konferenza d-dinja\"\n","word = \"mil-dinja\" # check how many tokens it breaks into and how that affects lang model scores\n","word = \"id-\"\n","word = \"fil- linja .\"\n","word = \"m'\" \n","word = \"a\"\n","word = \"uffiċjali\"\n","word = \"tielgħa\"\n","word = \"il-\"\n","# word = \"[għandhomx\" \n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['charmodel_score'],ascending=False)\n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['wordmodel_score'],ascending=False)\n","# sorted([(wordmodel.score(x),x) for x in merged],key=lambda x: -x[0])\n","\n","def generate_table(word):\n","    small_cc = translit_and_rank_options(word,name='small_cc',fsttype='non-det',backoffs=[baby_closed_class])\n","    augmented_cc = translit_and_rank_options(word,name='augmented_cc',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class])\n","    deterministic = translit_and_rank_options(word,name='deterministic',fsttype='det')    \n","    \n","    return (deterministic,small_cc,augmented_cc)\n","   \n","a,b,c = generate_table(word)\n","a = pd.DataFrame(a)\n","b = pd.DataFrame(b)\n","c = pd.DataFrame(c)\n","a.merge(b,how='outer').merge(c,how='outer').sort_values('wordmodel_score',ascending=False)[[\n","        'translit',\n","        'deterministic',\n","        'small_cc',\n","        'augmented_cc',\n","        'translit_stripped',\n","        'word_raw',\n","        'word_lowered',\n","        'wordmodel_score',\n","        'charmodel_score',\n","        'capitalized',\n","        'in_langmodel',\n","        'subtokens',\n","        'subtokens_lowest_ties',\n","        ]]"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# word_hist = word_hist\n","# mudtdev_translit = pd.concat(word_hist['sent'].iloc[:].apply(translit_and_rank_options).values)\n","def translit_dataset(word_hist):\n","    words_translita = []\n","    words_translitb = []\n","    words_translitc = []\n","    for word,freq in word_hist.values[:]:\n","        a,b,c = generate_table(word)    \n","        a['freq'] = freq\n","        b['freq'] = freq\n","        c['freq'] = freq\n","        # options.update({'freq':freq})\n","        words_translita.append(a)\n","        words_translitb.append(b)\n","        words_translitc.append(c)\n","    \n","    words_translit_exploded0 = pd.DataFrame(words_translita).explode(['translit','deterministic','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])#.drop_duplicates(['word_raw','translit'])\n","    words_translit_exploded1 = pd.DataFrame(words_translitb).explode(['translit','small_cc','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])#.drop_duplicates(['word_raw','translit'])\n","    words_translit_exploded2 = pd.DataFrame(words_translitc).explode(['translit','augmented_cc','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])#.drop_duplicates(['word_raw','translit'])\n","    words_translit_exploded = words_translit_exploded0.merge(words_translit_exploded1,how='outer').merge(words_translit_exploded2,how='outer').sort_values('wordmodel_score',ascending=False)[[\n","            'freq',\n","            'word_raw',\n","            'word_lowered',\n","            'translit',\n","            'deterministic',\n","            'small_cc',\n","            'augmented_cc',\n","            'translit_stripped',\n","            'wordmodel_score',\n","            'charmodel_score',\n","            'capitalized',\n","            'in_langmodel',\n","            'subtokens',\n","            'subtokens_lowest_ties',\n","            ]].sort_values(['freq','word_lowered'],ascending=False).reset_index(drop=True)\n","\n","    "]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mudt_translit \u001b[39m=\u001b[39m translit_dataset(mudt)\n","Cell \u001b[0;32mIn[27], line 7\u001b[0m, in \u001b[0;36mtranslit_dataset\u001b[0;34m(word_hist)\u001b[0m\n\u001b[1;32m      5\u001b[0m words_translitb \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m words_translitc \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m word,freq \u001b[39min\u001b[39;00m word_hist\u001b[39m.\u001b[39mvalues[:]:\n\u001b[1;32m      8\u001b[0m     a,b,c \u001b[39m=\u001b[39m generate_table(word)    \n\u001b[1;32m      9\u001b[0m     a[\u001b[39m'\u001b[39m\u001b[39mfreq\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m freq\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["mudt_translit = translit_dataset(mudt)\n","len(mudt_translit),len(mudt_translit),len(mudt_translit)/len(mudt_translit['word_raw'].unique())\n","mapa_translit = translit_dataset(mapa)\n","len(mapa_translit),len(mapa_translit),len(mapa_translit)/len(mapa_translit['word_raw'].unique())\n","mlrs_translit = translit_dataset(mlrs)\n","len(mlrs_translit),len(mlrs_translit),len(mlrs_translit)/len(mlrs_translit['word_raw'].unique())\n","sa_translit = translit_dataset(sa)\n","len(sa_translit),len(sa_translit),len(sa_translit)/len(sa_translit['word_raw'].unique())"]},{"cell_type":"code","execution_count":266,"metadata":{},"outputs":[{"data":{"text/plain":["(278305, 278305, 32.85385432652579)"]},"execution_count":266,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":267,"metadata":{},"outputs":[],"source":["mudt_translit.to_csv('mudt_transliterated_tuples.tsv',sep='\\t')"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["char_hist.to_clipboard()"]},{"cell_type":"code","execution_count":423,"metadata":{},"outputs":[],"source":["def translit_sent(sent):\n","    lattice = []\n","    for word in sent.split():\n","        optionsdf = translit_and_rank_options(word)\n","        options = optionsdf['merged'].values\n","        lattice.append(options)\n","\n","    return list([' '.join(x) for x in product(*lattice)])\n","        \n","def score_generated_sentences(sentences):\n","    return sorted([(x,model.score(x)) for x in sentences],key=lambda y: -y[1])\n","\n","\n","# score_generated_sentences(translit_sentence('malta magħrufa uffiċjalment bħala',cutoff=1))\n","\n","sentout = translit_sent(\"kien bilqiegħda f'dik il-parti\")"]},{"cell_type":"code","execution_count":424,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>كان بلقعدة في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>كان بلقاعدة في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>كان بلقعده في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>كان بلقعدة في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>كان بلقاعدة في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>كان بلقعده في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>كان بلقعدة في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>كان بلقاعدة في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>كان بلقعده في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         sent      score\n","0   كان بلقعدة في ديك البارتي -23.318352\n","3  كان بلقاعدة في ديك البارتي -23.318352\n","6   كان بلقعده في ديك البارتي -23.318352\n","1    كان بلقعدة في ديك البرتي -23.817825\n","4   كان بلقاعدة في ديك البرتي -23.817825\n","7    كان بلقعده في ديك البرتي -23.817825\n","2    كان بلقعدة في ديك البرطي -23.861692\n","5   كان بلقاعدة في ديك البرطي -23.861692\n","8    كان بلقعده في ديك البرطي -23.861692"]},"execution_count":424,"metadata":{},"output_type":"execute_result"}],"source":["dfsentout = pd.DataFrame({'sent':sentout})\n","dfsentout['score'] = dfsentout['sent'].apply(wordmodel.score)\n","dfsentout.sort_values('score',ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"maltifst","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
