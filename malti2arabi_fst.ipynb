{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15725,"status":"ok","timestamp":1680947155928,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"zTPm67tFHXYB","outputId":"2be2bbdb-6f14-4a4d-ab90-5440400781cc"},"outputs":[],"source":["# !git clone https://github.com/fadhleryani/malti_arabi_fst.git\n","# # !git pull\n","\n","# %pip install pynini\n","# %pip install pyfoma"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1680772861174,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"MgN2ht6q3QAH","outputId":"0a90890b-21b8-4e93-a193-3bc2306d3dc8"},"outputs":[],"source":["# %cd malti_arabi_fst"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"dn2vYkczBeMZ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/Caskroom/miniconda/base/envs/maltifst/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pynini as pn\n","import kenlm\n","from itertools import product\n","import pyconll\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/aggregated_country/lm/word/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n","Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/aggregated_country/lm/char/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n"]}],"source":["wordmodel = kenlm.Model('aggregated_country/lm/word/tn-maghreb.arpa')\n","charmodel = kenlm.Model('aggregated_country/lm/char/tn-maghreb.arpa')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mudt # of sents 2074\n","# of words 8471\n","# of chars 75\n"]}],"source":["dev = pyconll.load_from_file('mt_mudt-ud/mt_mudt-ud-dev.conllu')\n","train = pyconll.load_from_file('mt_mudt-ud/mt_mudt-ud-train.conllu')\n","test = pyconll.load_from_file('mt_mudt-ud/mt_mudt-ud-test.conllu')\n","\n","mudt = dev._sentences + train._sentences + test._sentences\n","\n","print('mudt # of sents',len(mudt))\n","\n","keys = [\"id\",\"form\",\"lemma\",\"upos\",\"xpos\",\"feats\",\"head\",\"deprel\",\"deps\",\"misc\"]\n","\n","sents = []\n","for sent in mudt:\n","    toks = [pd.Series({'sent_id':sent.id,'sent':sent.text})]\n","    # toks = []\n","    for tok in sent:\n","        tokdict = {'sent_id':sent.id}\n","        tokdict.update( {k:tok.__getattribute__(k) for k in keys})\n","        toks.append (pd.Series(tokdict))\n","\n","    sents.append(pd.DataFrame(toks))\n","\n","df = pd.concat(sents)\n","\n","# word_hist\n","word_hist = df['form'].dropna().value_counts().reset_index()\n","# word_hist.to_clipboard()\n","print('# of words',len(word_hist))\n","# char hist\n","char_hist = pd.DataFrame([y for x in df['sent'].dropna().str.casefold() for y in x]).value_counts()\n","# char_hist.to_clipboard()\n","print('# of chars',len(char_hist))\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["closedclass = pd.read_csv('mappings/closed_class_mappings.tsv',sep='\\t',header=None) # already unique \n","closedclass = dict(closedclass.values)\n","\n"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["\n","malti2arabi_2char = pn.string_file('mappings/malti2arabi_2char.map').optimize()\n","arabic2arabic = pn.string_file('mappings/arabic2arabic.map').optimize()\n","malti2arabi_1char = pn.string_file('mappings/malti2arabi_1char.map').optimize()\n","shadda = pn.string_file('mappings/shadda.map').optimize()\n","final_vowels = pn.string_file('mappings/final_vowels.map').optimize()\n","special = pn.string_file('mappings/special.map').optimize()\n","alif_initial = pn.string_file('mappings/alif_initial.map').optimize()\n","baby_closed_class = pn.string_file('mappings/baby_closed_class.map').optimize()\n","\n","sigma_malti = pn.project(malti2arabi_1char,'input')\n","sigma_arabi = pn.project(arabic2arabic,'output') \n","\n","# SIGMA\n","sigma_in = pn.project(pn.union(malti2arabi_1char,special,arabic2arabic,final_vowels),'input')\n","sigma = pn.project(pn.union(sigma_in,special,final_vowels),'output')\n","sigma = pn.union(sigma,\"-\").optimize() \n","\n","rwr_first_fsts = pn.union(\n","    malti2arabi_2char,\n","    shadda,\n","    final_vowels,\n","    alif_initial,\n",").optimize()\n","\n","rwr_first = pn.cdrewrite(rwr_first_fsts,\"\",\"\",sigma.closure())\n","\n","second_fsts = pn.union(\n","    malti2arabi_1char,\n","    arabic2arabic, \n","    special,\n",").optimize()\n","\n","translit_fst = rwr_first @ second_fsts.closure()\n","\n","translit_deterministic_fst = pn.string_file('mappings_deterministic/malti2arabi_1char_vowels_short.map').optimize().closure()\n","\n","diacs = 'ًٌٍَُِّْ'\n","dediac_cross = pn.string_file('mappings/dediac.map')\n","dediac = pn.cdrewrite(dediac_cross,'','',sigma.closure())\n","\n","augmented_closed_class = pn.string_file('mappings/augmented_closed_class.map').optimize()\n","\n","words = pn.string_file('tn-maghreb-words.txt').optimize() @ dediac"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# paths = get_paths((\"<BOS>mil-<EOS>\"  @ baby_closed_class @ transcriber  )),get_paths((\"<BOS>fok<EOS>\"   @ transcriber  ))\n","# paths,len(paths)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def dediac_fst(text):\n","    text = text.replace('[','\\[').replace(']','\\]')\n","    try:\n","        return (text @ dediac).string()\n","    except:\n","        return np.nan\n","    \n","words_df= pd.read_fwf('tn-maghreb-words.txt',header=None).rename(columns={0:'words'})\n","words_df['dediac'] = pd.Series([dediac_fst(x) for x in words_df['words']])\n","\n","# words_df"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_raw</th>\n","      <th>word_lowered</th>\n","      <th>translit</th>\n","      <th>translit_stripped</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>closed_class</th>\n","      <th>subtokens</th>\n","      <th>subtokens_lowest_ties</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>طالعة</td>\n","      <td>طالعة</td>\n","      <td>-6.705869</td>\n","      <td>-6.622174</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>#na</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  word_raw word_lowered translit translit_stripped  wordmodel_score   \n","0  tielgħa      tielgħa    طالعة             طالعة        -6.705869  \\\n","\n","   charmodel_score  capitalized  in_langmodel closed_class  subtokens   \n","0        -6.622174        False          True          #na          2  \\\n","\n","   subtokens_lowest_ties  \n","0                      1  "]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["def get_paths(fst,words_only=False):\n","    paths = list(fst.paths().items())\n","    if words_only:\n","        return [x[1] for x in paths]\n","    else:\n","        return paths\n","\n","\n","\n","def translit_fst(tok,backoff_fsts=[baby_closed_class,augmented_closed_class]):\n","    tok = tok.replace('[','\\[').replace(']','\\]')\n","    tok = (f'<BOS>{tok}<EOS>')\n","    # if type=='det':\n","    #     return tok @ deterministic_transcriber @ dediac\n","    if backoff_fsts:\n","        backoff =  tok @ pn.union(*backoff_fsts).optimize() @ dediac\n","        if get_paths(backoff):\n","            return backoff\n","        else:\n","            return tok  @ transcriber @ dediac\n","    else:\n","        return tok  @ transcriber @ dediac\n","\n","def filter_edge_diacritics(options):\n","    return [y for y in options if y[0] not in diacs and y[-1] not in diacs]\n","\n","def translit_deterministic(lowered):\n","    try:\n","        return (lowered @ translit_deterministic_fst).string()\n","    except:\n","        print('deterministic fst error on:',lowered)\n","        return '#na'\n","\n","def translit_word(lowered_tok,backoffs): #select on merged but return unmerged\n","\n","    tok_fst = translit_fst(lowered_tok,backoffs)\n","    translit_toks = get_paths(tok_fst,words_only=True) \n","    if not translit_toks:\n","        return ['#NA']\n","    try:\n","        translit_toks = filter_edge_diacritics(translit_toks) \n","    except:\n","        print('err filtering diacs',translit_toks,lowered_tok)\n","    \n","    translit_toks = [ dediac_fst(x) for x in translit_toks]  # dediacritize\n","    return translit_toks\n","    \n","\n","langmodelset =  set(words_df['dediac'])\n","\n","def count_subtokens(text, tokenizer):\n","    text = [x.rstrip('+') for x in text]\n","    return tokenizer(text, add_special_tokens=False, return_length=True)[\"length\"]\n","\n","\n","def translit_and_rank_options(word,fsttype='non-deterministic',backoffs=[baby_closed_class,augmented_closed_class]):\n","  \n","    lowered = word.lower()\n","    translit_dict = {\n","        'word_raw':word,\n","        'word_lowered':lowered,\n","        }\n","    \n","    if fsttype == 'deterministic':\n","        translit = translit_deterministic(lowered)\n","    if fsttype == 'non-deterministic':\n","        translit = translit_word(lowered,backoffs)\n","\n","    translit_dict['translit'] = translit\n"," \n","    translit_dict['translit_stripped'] = [x.rstrip('+') for x in translit_dict['translit']]\n","    translit_dict['wordmodel_score'] = [wordmodel.score(x) for x in translit_dict['translit_stripped']]\n","    translit_dict['charmodel_score'] = [charmodel.score(' '.join(x)) for x in translit_dict['translit_stripped'] ]\n","    translit_dict['capitalized'] = word[0].isupper() # TODO: what about letter after sink as in 'L-Innu', does it matter?\n","    translit_dict['in_langmodel'] = [x in langmodelset for x in translit_dict['translit_stripped']]\n","    translit_dict['closed_class'] = [closedclass.get(x,'#na') for x in translit_dict['translit_stripped']]\n","    translit_dict['subtokens'] = count_subtokens(translit_dict['translit_stripped'], tokenizer)\n","    translit_dict['subtokens_lowest_ties'] = sum(np.array(translit_dict['subtokens']) == max(translit_dict['subtokens']))\n","\n","    return translit_dict\n","    \n","\n","word = \"t'\"\n","word = \"L-Innu\"\n","word = \"din\"\n","word = \"f'dik\"\n","word = \"d-dinja\"\n","word = \"f'dil-konferenza d-dinja\"\n","word = \"mil-dinja\" # check how many tokens it breaks into and how that affects lang model scores\n","word = \"id-\"\n","word = \"fil- linja .\"\n","word = \"il-\"\n","word = \"m'\" \n","word = \"a\"\n","word = \"uffiċjali\"\n","word = \"tielgħa\"\n","# word = \"[għandhomx\" \n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['charmodel_score'],ascending=False)\n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['wordmodel_score'],ascending=False)\n","# sorted([(wordmodel.score(x),x) for x in merged],key=lambda x: -x[0])\n","d = translit_and_rank_options(word,backoffs=[baby_closed_class])\n","d = translit_and_rank_options(word,backoffs=[baby_closed_class,augmented_closed_class])\n","# pd.DataFrame(data=d,index=range(max([len(x) for x in d.values()])))\n","# x = translit_and_rank_options(\"simboli!\")\n","pd.DataFrame(d).sort_values('wordmodel_score',ascending=False)\n","\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# tuple(original_word,\n","# boolean(capitalized or not),\n","# closed class mapping or nill    ,\n","# boolean(Exists or not),\n","# wordmodel score,\n","# charactermodel score,\n","# kurts fertility)\n","\n","# ADD\n","# freq counts (including capitalized and ignoring)\n","# merge and uniq all sets\n","\n","# do example with dik id-dinja / fil- dinja\n","# think about redoing closed class to avoid changing number of tokens\n","\n","# keep track if length of input is same as output (number of tokens)\n","\n","# assume tokenized data (like mudt tokens)?"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["# word_hist = word_hist\n","# mudtdev_translit = pd.concat(word_hist['sent'].iloc[:].apply(translit_and_rank_options).values)\n","words_translit = []\n","for word,freq in word_hist.values[:]:\n","    options = translit_and_rank_options(word,useclosedclass=False)\n","    options.update({'freq':freq})\n","    words_translit.append(options)\n","\n","mudt_translit = pd.DataFrame(words_translit)\n"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["mudt_translit_exploded = mudt_translit.explode(['translit','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens']).drop_duplicates(['word_raw','translit'])"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["(268013, 8471, 31.638885609727303)"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["len(mudt_translit_exploded),len(mudt_translit),len(mudt_translit_exploded)/len(mudt_translit)"]},{"cell_type":"code","execution_count":550,"metadata":{},"outputs":[],"source":["mudt_translit_exploded.to_csv('mudt_transliterated_tuples.tsv',sep='\\t')"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["char_hist.to_clipboard()"]},{"cell_type":"code","execution_count":423,"metadata":{},"outputs":[],"source":["def translit_sent(sent):\n","    lattice = []\n","    for word in sent.split():\n","        optionsdf = translit_and_rank_options(word)\n","        options = optionsdf['merged'].values\n","        lattice.append(options)\n","\n","    return list([' '.join(x) for x in product(*lattice)])\n","        \n","def score_generated_sentences(sentences):\n","    return sorted([(x,model.score(x)) for x in sentences],key=lambda y: -y[1])\n","\n","\n","# score_generated_sentences(translit_sentence('malta magħrufa uffiċjalment bħala',cutoff=1))\n","\n","sentout = translit_sent(\"kien bilqiegħda f'dik il-parti\")"]},{"cell_type":"code","execution_count":424,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>كان بلقعدة في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>كان بلقاعدة في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>كان بلقعده في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>كان بلقعدة في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>كان بلقاعدة في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>كان بلقعده في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>كان بلقعدة في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>كان بلقاعدة في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>كان بلقعده في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         sent      score\n","0   كان بلقعدة في ديك البارتي -23.318352\n","3  كان بلقاعدة في ديك البارتي -23.318352\n","6   كان بلقعده في ديك البارتي -23.318352\n","1    كان بلقعدة في ديك البرتي -23.817825\n","4   كان بلقاعدة في ديك البرتي -23.817825\n","7    كان بلقعده في ديك البرتي -23.817825\n","2    كان بلقعدة في ديك البرطي -23.861692\n","5   كان بلقاعدة في ديك البرطي -23.861692\n","8    كان بلقعده في ديك البرطي -23.861692"]},"execution_count":424,"metadata":{},"output_type":"execute_result"}],"source":["dfsentout = pd.DataFrame({'sent':sentout})\n","dfsentout['score'] = dfsentout['sent'].apply(wordmodel.score)\n","dfsentout.sort_values('score',ascending=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"maltifst","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
