{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15725,"status":"ok","timestamp":1680947155928,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"zTPm67tFHXYB","outputId":"2be2bbdb-6f14-4a4d-ab90-5440400781cc"},"outputs":[],"source":["# !git clone https://github.com/fadhleryani/malti_arabi_fst.git\n","# # !git pull\n","\n","# %pip install pynini\n","# %pip install pyfoma"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1680772861174,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"MgN2ht6q3QAH","outputId":"0a90890b-21b8-4e93-a193-3bc2306d3dc8"},"outputs":[],"source":["# %cd malti_arabi_fst"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dn2vYkczBeMZ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/Caskroom/miniconda/base/envs/maltifst/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pynini as pn\n","import kenlm\n","from itertools import product\n","import pyconll\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/data/arabi_data/arabic_lm/aggregated_country/lm/word/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n","Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/data/arabi_data/arabic_lm/aggregated_country/lm/char/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n"]}],"source":["wordmodel = kenlm.Model('data/arabi_data/arabic_lm/aggregated_country/lm/word/tn-maghreb.arpa')\n","charmodel = kenlm.Model('data/arabi_data/arabic_lm/aggregated_country/lm/char/tn-maghreb.arpa')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def merge_conllu(dataset,charhist=False):\n","    dev = pyconll.load_from_file(f'data/malti_data/{dataset}/dev.conllu')\n","    train = pyconll.load_from_file(f'data/malti_data/{dataset}/train.conllu')\n","    test = pyconll.load_from_file(f'data/malti_data/{dataset}/test.conllu')\n","    allsets = dev._sentences + train._sentences + test._sentences\n","\n","    print(f'# of sents in {dataset}',len(allsets))\n","\n","    keys = [\"id\",\"form\",\"lemma\",\"upos\",\"xpos\",\"feats\",\"head\",\"deprel\",\"deps\",\"misc\"]\n","\n","    sents = []\n","    for sent in allsets:\n","        # toks = [pd.Series({'sent_id':sent.id,'sent':sent.text})]\n","        toks = []\n","        for tok in sent:\n","            tokdict = {'sent_id':sent.id}\n","            tokdict.update( {k:tok.__getattribute__(k) for k in keys})\n","            toks.append (pd.Series(tokdict))\n","        sents.append(pd.DataFrame(toks))\n","    df = pd.concat(sents)    \n","    # word_hist\n","    word_hist = df['form'].dropna().value_counts().reset_index()\n","    # word_hist.to_clipboard()\n","    print(f'# of words in {dataset}',len(word_hist))\n","    # # char hist\n","    char_hist = pd.DataFrame([y for x in df['form'].dropna().str.casefold() for y in x]).value_counts()\n","    # char_hist.to_clipboard()\n","    print(f'# of chars {dataset}',len(char_hist))\n","    return word_hist"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["# of sents in MLRS POS 6167\n","# of words in MLRS POS 15774\n","# of chars MLRS POS 81\n","# of sents in Sentiment Analysis 851\n","# of words in Sentiment Analysis 5425\n","# of chars Sentiment Analysis 70\n","# of sents in MAPA 8763\n","# of words in MAPA 19059\n","# of chars MAPA 143\n","# of sents in mt_mudt-ud 2074\n","# of words in mt_mudt-ud 8471\n","# of chars mt_mudt-ud 74\n"]}],"source":["mlrs = merge_conllu('MLRS POS')\n","sa = merge_conllu('Sentiment Analysis')\n","mapa = merge_conllu('MAPA')\n","mudt = merge_conllu('mt_mudt-ud')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# closedclass = pd.read_csv('mappings/closed_class_mappings.tsv',sep='\\t',header=None) # already unique \n","# closedclass = dict(closedclass.values)\n","\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["\n","malti2arabi_2char = pn.string_file('mappings/malti2arabi_2char.map').optimize()\n","arabic2arabic = pn.string_file('mappings/arabic2arabic.map').optimize()\n","malti2arabi_1char = pn.string_file('mappings/malti2arabi_1char.map').optimize()\n","shadda = pn.string_file('mappings/shadda.map').optimize()\n","final_vowels = pn.string_file('mappings/final_vowels.map').optimize()\n","special = pn.string_file('mappings/special.map').optimize()\n","alif_initial = pn.string_file('mappings/alif_initial.map').optimize()\n","baby_closed_class = pn.string_file('mappings/baby_closed_class.map').optimize()\n","\n","sigma_malti = pn.project(malti2arabi_1char,'input')\n","sigma_arabi = pn.project(arabic2arabic,'output') \n","\n","# SIGMA\n","sigma_in = pn.project(pn.union(malti2arabi_1char,special,arabic2arabic,final_vowels),'input')\n","sigma = pn.project(pn.union(sigma_in,special,final_vowels),'output')\n","sigma = pn.union(sigma,\"-\").optimize() \n","\n","rwr_first_fsts = pn.union(\n","    malti2arabi_2char,\n","    shadda,\n","    final_vowels,\n","    alif_initial,\n",").optimize()\n","\n","rwr_first = pn.cdrewrite(rwr_first_fsts,\"\",\"\",sigma.closure())\n","\n","second_fsts = pn.union(\n","    malti2arabi_1char,\n","    arabic2arabic, \n","    special,\n",").optimize()\n","\n","translit_fst = rwr_first @ second_fsts.closure()\n","\n","malti2arabi_det= pn.string_file('mappings_deterministic/malti2arabi_1char_vowels_short.map').optimize()\n","special_deterministic = pn.string_file('mappings_deterministic/special_deterministic.map').optimize()\n","\n","diacs = 'ًٌٍَُِّْ'\n","dediac_cross = pn.string_file('mappings/dediac.map')\n","dediac = pn.cdrewrite(dediac_cross,'','',sigma.closure())\n","\n","augmented_closed_class = pn.string_file('mappings/augmented_closed_class.map').optimize()\n","\n","words = pn.string_file('data/arabi_data/tn-maghreb-words.txt').optimize() @ dediac"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# paths = get_paths((\"<BOS>mil-<EOS>\"  @ baby_closed_class @ transcriber  )),get_paths((\"<BOS>fok<EOS>\"   @ transcriber  ))\n","# paths,len(paths)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def dediac_fst(text):\n","    text = text.replace('[','\\[').replace(']','\\]')\n","    try:\n","        return (text @ dediac).string()\n","    except:\n","        return np.nan\n","    \n","words_df= pd.read_fwf('data/arabi_data/tn-maghreb-words.txt',header=None).rename(columns={0:'words'})\n","words_df['dediac'] = pd.Series([dediac_fst(x) for x in words_df['words']])\n","\n","# words_df"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>translit</th>\n","      <th>det</th>\n","      <th>det_smallcc</th>\n","      <th>det_fullcc</th>\n","      <th>nondet</th>\n","      <th>nondet_smallcc</th>\n","      <th>nondet_fullcc</th>\n","      <th>translit_stripped</th>\n","      <th>word_raw</th>\n","      <th>word_lowered</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>subtokens</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>طالعة</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>طالعة</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-6.705869</td>\n","      <td>-6.622174</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>طالعة</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>NaN</td>\n","      <td>طالعة</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-6.705869</td>\n","      <td>-6.622174</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>طالعه</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالعه</td>\n","      <td>NaN</td>\n","      <td>طالعه</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-7.818769</td>\n","      <td>-7.795122</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>تلجح</td>\n","      <td>تلجح</td>\n","      <td>تلجح</td>\n","      <td>تلجح</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تلجح</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-9.504936</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>طالغه</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالغه</td>\n","      <td>NaN</td>\n","      <td>طالغه</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.538343</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>طالغة</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالغة</td>\n","      <td>NaN</td>\n","      <td>طالغة</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.012894</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>طالغا</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالغا</td>\n","      <td>NaN</td>\n","      <td>طالغا</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-11.608114</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>طالعى</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالعى</td>\n","      <td>NaN</td>\n","      <td>طالعى</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-9.582643</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>طالعا</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالعا</td>\n","      <td>NaN</td>\n","      <td>طالعا</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-11.131311</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>تالغى</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالغى</td>\n","      <td>NaN</td>\n","      <td>تالغى</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.442297</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>تالغه</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالغه</td>\n","      <td>NaN</td>\n","      <td>تالغه</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.737543</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>تالغة</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالغة</td>\n","      <td>NaN</td>\n","      <td>تالغة</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.212093</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>تالغا</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالغا</td>\n","      <td>NaN</td>\n","      <td>تالغا</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-11.807315</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>تالعى</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالعى</td>\n","      <td>NaN</td>\n","      <td>تالعى</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.634503</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>تالعه</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالعه</td>\n","      <td>NaN</td>\n","      <td>تالعه</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-9.986337</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>تالعة</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالعة</td>\n","      <td>NaN</td>\n","      <td>تالعة</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-9.904209</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>تالعا</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>تالعا</td>\n","      <td>NaN</td>\n","      <td>تالعا</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-12.306542</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>طالغى</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>طالغى</td>\n","      <td>NaN</td>\n","      <td>طالغى</td>\n","      <td>tielgħa</td>\n","      <td>tielgħa</td>\n","      <td>-8.091814</td>\n","      <td>-10.243097</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   translit   det det_smallcc det_fullcc nondet nondet_smallcc nondet_fullcc   \n","1     طالعة   NaN         NaN        NaN  طالعة            NaN         طالعة  \\\n","11    طالعة   NaN         NaN        NaN    NaN          طالعة           NaN   \n","12    طالعه   NaN         NaN        NaN    NaN          طالعه           NaN   \n","0      تلجح  تلجح        تلجح       تلجح    NaN            NaN           NaN   \n","16    طالغه   NaN         NaN        NaN    NaN          طالغه           NaN   \n","15    طالغة   NaN         NaN        NaN    NaN          طالغة           NaN   \n","14    طالغا   NaN         NaN        NaN    NaN          طالغا           NaN   \n","13    طالعى   NaN         NaN        NaN    NaN          طالعى           NaN   \n","10    طالعا   NaN         NaN        NaN    NaN          طالعا           NaN   \n","9     تالغى   NaN         NaN        NaN    NaN          تالغى           NaN   \n","8     تالغه   NaN         NaN        NaN    NaN          تالغه           NaN   \n","7     تالغة   NaN         NaN        NaN    NaN          تالغة           NaN   \n","6     تالغا   NaN         NaN        NaN    NaN          تالغا           NaN   \n","5     تالعى   NaN         NaN        NaN    NaN          تالعى           NaN   \n","4     تالعه   NaN         NaN        NaN    NaN          تالعه           NaN   \n","3     تالعة   NaN         NaN        NaN    NaN          تالعة           NaN   \n","2     تالعا   NaN         NaN        NaN    NaN          تالعا           NaN   \n","17    طالغى   NaN         NaN        NaN    NaN          طالغى           NaN   \n","\n","   translit_stripped word_raw word_lowered  wordmodel_score  charmodel_score   \n","1              طالعة  tielgħa      tielgħa        -6.705869        -6.622174  \\\n","11             طالعة  tielgħa      tielgħa        -6.705869        -6.622174   \n","12             طالعه  tielgħa      tielgħa        -7.818769        -7.795122   \n","0               تلجح  tielgħa      tielgħa        -8.091814        -9.504936   \n","16             طالغه  tielgħa      tielgħa        -8.091814       -10.538343   \n","15             طالغة  tielgħa      tielgħa        -8.091814       -10.012894   \n","14             طالغا  tielgħa      tielgħa        -8.091814       -11.608114   \n","13             طالعى  tielgħa      tielgħa        -8.091814        -9.582643   \n","10             طالعا  tielgħa      tielgħa        -8.091814       -11.131311   \n","9              تالغى  tielgħa      tielgħa        -8.091814       -10.442297   \n","8              تالغه  tielgħa      tielgħa        -8.091814       -10.737543   \n","7              تالغة  tielgħa      tielgħa        -8.091814       -10.212093   \n","6              تالغا  tielgħa      tielgħa        -8.091814       -11.807315   \n","5              تالعى  tielgħa      tielgħa        -8.091814       -10.634503   \n","4              تالعه  tielgħa      tielgħa        -8.091814        -9.986337   \n","3              تالعة  tielgħa      tielgħa        -8.091814        -9.904209   \n","2              تالعا  tielgħa      tielgħa        -8.091814       -12.306542   \n","17             طالغى  tielgħa      tielgħa        -8.091814       -10.243097   \n","\n","    capitalized  in_langmodel  subtokens  \n","1         False          True          2  \n","11        False          True          2  \n","12        False          True          2  \n","0         False         False          2  \n","16        False         False          2  \n","15        False         False          2  \n","14        False         False          2  \n","13        False         False          2  \n","10        False         False          2  \n","9         False         False          2  \n","8         False         False          2  \n","7         False         False          2  \n","6         False         False          2  \n","5         False         False          2  \n","4         False         False          2  \n","3         False         False          2  \n","2         False         False          2  \n","17        False         False          2  "]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["def get_paths(fst,words_only=False):\n","    paths = list(fst.paths().items())\n","    if words_only:\n","        return [x[1] for x in paths]\n","    else:\n","        return paths\n","\n","\n","\n","def apply_translit_fst(tok,backoff_fsts=[baby_closed_class,augmented_closed_class]):\n","    tok = tok.replace('[','\\[').replace(']','\\]')\n","    tok = (f'<BOS>{tok}<EOS>')\n","    # if type=='det':\n","    #     return tok @ deterministic_transcriber @ dediac\n","    if backoff_fsts:\n","        backoff =  tok @ pn.union(*backoff_fsts).optimize() @ dediac\n","        if get_paths(backoff):\n","            return backoff\n","        else:\n","            return tok  @ translit_fst @ dediac\n","    else:\n","        return tok  @ translit_fst @ dediac\n","\n","def filter_edge_diacritics(options):\n","    return [y for y in options if y[0] not in diacs and y[-1] not in diacs]\n","\n","def translit_deterministic(lowered,backoffs=[]):\n","    lowered = lowered.replace('[','\\[').replace(']','\\]') \n","    if backoffs:\n","        backofflowered = f'<BOS>{lowered}<EOS>'\n","        backoff = backofflowered @ pn.union(*backoffs).optimize() @ dediac\n","        if len(get_paths(backoff))==1:\n","            return backoff.string()\n","        elif len(get_paths(backoff))>1:\n","            print('error: fst is NOT deterministic on:',lowered)\n","            return '#na'\n","    # default\n","    try:\n","        maptranslit = (lowered @ pn.union(malti2arabi_det,special_deterministic).closure().optimize() @ dediac).string()\n","        return maptranslit\n","    except:\n","        print('error detfst on:',lowered)\n","        return '#na'\n","            \n","\n","def translit_word(lowered_tok,backoffs): #select on merged but return unmerged\n","\n","    tok_fst = apply_translit_fst(lowered_tok,backoffs)\n","    translit_toks = get_paths(tok_fst,words_only=True) \n","    if not translit_toks:\n","        return ['#NA']\n","    try:\n","        translit_toks = filter_edge_diacritics(translit_toks) \n","    except:\n","        print('err filtering diacs',translit_toks,lowered_tok)\n","    \n","    translit_toks = [ dediac_fst(x) for x in translit_toks]  # dediacritize\n","    return translit_toks\n","    \n","\n","langmodelset =  set(words_df['dediac'])\n","\n","def count_subtokens(text, tokenizer):\n","    return tokenizer(text, add_special_tokens=False, return_length=True)[\"length\"]\n","\n","\n","def translit_and_rank_options(word,name='translit',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class]):\n","  \n","    lowered = word.lower()\n","    translit_dict = {\n","        'word_raw':word,\n","        'word_lowered':lowered,\n","        }\n","    \n","    if fsttype == 'det':\n","        translit = [translit_deterministic(lowered)]\n","    elif fsttype == 'non-det':\n","        translit = translit_word(lowered,backoffs)\n","    else:\n","        raise Exception('wrong fsttype')\n","\n","    translit_dict[name] = translit\n","    translit_dict['translit'] = translit # keep this, in order to merge later\n","    translit_dict['translit_stripped'] = [x.rstrip('+') for x in translit]\n","    translit_dict['wordmodel_score'] = [wordmodel.score(x) for x in translit_dict['translit_stripped']]\n","    translit_dict['charmodel_score'] = [charmodel.score(' '.join(x)) for x in translit_dict['translit_stripped'] ]\n","    translit_dict['capitalized'] = word[0].isupper() # TODO: what about letter after sink as in 'L-Innu', does it matter?\n","    translit_dict['in_langmodel'] = [x in langmodelset for x in translit_dict['translit_stripped']]\n","    translit_dict['subtokens'] = count_subtokens(translit_dict['translit_stripped'], tokenizer)\n","    translit_dict['subtokens_lowest_ties'] = sum(np.array(translit_dict['subtokens']) == min(translit_dict['subtokens']))\n","\n","    return translit_dict\n","    \n","\n","word = \"t'\"\n","word = \"L-Innu\"\n","word = \"din\"\n","word = \"f'dik\"\n","word = \"d-dinja\"\n","word = \"f'dil-konferenza d-dinja\"\n","word = \"mil-dinja\" # check how many tokens it breaks into and how that affects lang model scores\n","word = \"id-\"\n","word = \"fil- linja .\"\n","word = \"m'\" \n","word = \"a\"\n","word = \"uffiċjali\"\n","word = \"il-\"\n","word = \"tielgħa\"\n","# word = \"[għandhomx\" \n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['charmodel_score'],ascending=False)\n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['wordmodel_score'],ascending=False)\n","# sorted([(wordmodel.score(x),x) for x in merged],key=lambda x: -x[0])\n","\n","\n","\n","def generate_table(word):\n","    det = translit_and_rank_options(word,name='det',fsttype='det')    \n","    det_smallcc = translit_and_rank_options(word,name='det_smallcc',fsttype='det', backoffs=[baby_closed_class])    \n","    det_fullcc = translit_and_rank_options(word,name='det_fullcc',fsttype='det', backoffs=[baby_closed_class,augmented_closed_class])    \n","    nondet = translit_and_rank_options(word,name='nondet',fsttype='non-det')\n","    nondet_smallcc = translit_and_rank_options(word,name='nondet_smallcc',fsttype='non-det',backoffs=[baby_closed_class])\n","    nondet_fullcc = translit_and_rank_options(word,name='nondet_fullcc',fsttype='non-det',backoffs=[baby_closed_class,augmented_closed_class])\n","    \n","    return (det,det_smallcc,det_fullcc,nondet,nondet_smallcc,nondet_fullcc,)\n","   \n","det,det_smallcc,det_fullcc,nondet,nondet_smallcc,nondet_fullcc = generate_table(word)\n","det = pd.DataFrame(det)\n","det_smallcc = pd.DataFrame(det_smallcc)\n","det_fullcc = pd.DataFrame(det_fullcc)\n","nondet = pd.DataFrame(nondet)\n","nondet_smallcc = pd.DataFrame(nondet_smallcc)\n","nondet_fullcc = pd.DataFrame(nondet_fullcc)\n","\n","def merge_multiple(dfs=[det,det_smallcc,det_fullcc,nondet,nondet_smallcc,nondet_fullcc]):\n","    first = dfs[0]\n","    for df in dfs[1:]:\n","        first = first.merge(df,how='outer')\n","    \n","    return first.sort_values('wordmodel_score',ascending=False)[[\n","        'translit',\n","        'det',\n","        'det_smallcc',\n","        'det_fullcc',\n","        'nondet',\n","        'nondet_smallcc',\n","        'nondet_fullcc',        \n","        'translit_stripped',\n","        'word_raw',\n","        'word_lowered',\n","        'wordmodel_score',\n","        'charmodel_score',\n","        'capitalized',\n","        'in_langmodel',\n","        'subtokens',\n","        # 'subtokens_lowest_ties',\n","        ]]\n","\n","merged = merge_multiple()\n","merged"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["(['14ل'], '14+ل')"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["def translit_deterministic(lowered,backoffs=[]):\n","    lowered = lowered.replace('[','\\[').replace(']','\\]') \n","    if backoffs:\n","        backofflowered = f'<BOS>{lowered}<EOS>'\n","        backoff = backofflowered @ pn.union(*backoffs).optimize() @ dediac\n","        if len(get_paths(backoff))==1:\n","            return backoff.string()\n","        elif len(get_paths(backoff))>1:\n","            print('error: fst is NOT deterministic on:',lowered)\n","            return '#na'\n","    # default\n","    try:\n","        maptranslit = (lowered @ pn.union(malti2arabi_det,special_deterministic).closure().optimize() @ dediac).string()\n","        return maptranslit\n","    except:\n","        print('error detfst on:',lowered)\n","        return '#na'\n","        \n","            \n","    \n","translit_word(\"14-il\",backoffs=[baby_closed_class]),translit_deterministic(\"14-il\",backoffs=[baby_closed_class])\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["translit_deterministic('ab')"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["# word_hist = word_hist\n","# mudtdev_translit = pd.concat(word_hist['sent'].iloc[:].apply(translit_and_rank_options).values)\n","def translit_dataset(word_hist):\n","    \n","    detlist = []\n","    det_smallcclist = []\n","    det_fullcclist = []\n","    nondetlist = []\n","    nondet_smallcclist = []\n","    nondet_fullcclist = []\n","\n","    for word,freq in word_hist.values[:]:\n","        det, det_smallcc, det_fullcc, nondet, nondet_smallcc, nondet_fullcc = generate_table(word)\n","        det['freq'] = freq\n","        det_smallcc['freq'] = freq\n","        det_fullcc['freq'] = freq\n","        nondet['freq'] = freq\n","        nondet_smallcc['freq'] = freq\n","        nondet_fullcc    ['freq'] = freq\n","        \n","        detlist.append(det)\n","        det_smallcclist.append(det_smallcc)\n","        det_fullcclist.append(det_fullcc)\n","        nondetlist.append(nondet)\n","        nondet_smallcclist.append(nondet_smallcc)\n","        nondet_fullcclist.append(nondet_fullcc)\n","        \n","    \n","    detlist = pd.DataFrame(detlist).explode(['translit','detlist','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    det_smallcclist = pd.DataFrame(det_smallcclist).explode(['translit','det_smallcclist','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    det_fullcclist = pd.DataFrame(det_fullcclist).explode(['translit','det_fullcclist','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    nondetlist = pd.DataFrame(nondetlist).explode(['translit','nondetlist','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    nondet_smallcclist = pd.DataFrame(nondet_smallcclist).explode(['translit','nondet_smallcclist','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","    nondet_fullcclist = pd.DataFrame(nondet_fullcclist).explode(['translit','nondet_fullcclist','translit_stripped','wordmodel_score','charmodel_score','in_langmodel','subtokens'])\n","\n","    return merge_multiple(dfs=\n","                          [\n","detlist,\n","det_smallcclist,\n","det_fullcclist,\n","nondetlist,\n","nondet_smallcclist,\n","nondet_fullcclist,\n","                          ]\n","                          )\n","\n","    "]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["error detfst on: ×\n","error detfst on: ×\n","error detfst on: ×\n","error detfst on: \\rin\\[\n","error detfst on: \\rin\\[\n","error detfst on: \\rin\\[\n"]},{"ename":"NameError","evalue":"name 'detlistlist' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mudt_translit \u001b[39m=\u001b[39m translit_dataset(mudt)\n\u001b[1;32m      2\u001b[0m \u001b[39mlen\u001b[39m(mudt_translit),\u001b[39mlen\u001b[39m(mudt_translit),\u001b[39mlen\u001b[39m(mudt_translit)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(mudt_translit[\u001b[39m'\u001b[39m\u001b[39mword_raw\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())\n\u001b[1;32m      3\u001b[0m mapa_translit \u001b[39m=\u001b[39m translit_dataset(mapa)\n","Cell \u001b[0;32mIn[77], line 29\u001b[0m, in \u001b[0;36mtranslit_dataset\u001b[0;34m(word_hist)\u001b[0m\n\u001b[1;32m     25\u001b[0m     nondet_smallcclist\u001b[39m.\u001b[39mappend(nondet_smallcc)\n\u001b[1;32m     26\u001b[0m     nondet_fullcclist\u001b[39m.\u001b[39mappend(nondet_fullcc)\n\u001b[0;32m---> 29\u001b[0m detlist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(detlistlist)\u001b[39m.\u001b[39mexplode([\u001b[39m'\u001b[39m\u001b[39mtranslit\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdetlist\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtranslit_stripped\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwordmodel_score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcharmodel_score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39min_langmodel\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msubtokens\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m det_smallcclist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(det_smallcclistlist)\u001b[39m.\u001b[39mexplode([\u001b[39m'\u001b[39m\u001b[39mtranslit\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdet_smallcclist\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtranslit_stripped\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwordmodel_score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcharmodel_score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39min_langmodel\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msubtokens\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m det_fullcclist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(det_fullcclistlist)\u001b[39m.\u001b[39mexplode([\u001b[39m'\u001b[39m\u001b[39mtranslit\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdet_fullcclist\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtranslit_stripped\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwordmodel_score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcharmodel_score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39min_langmodel\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msubtokens\u001b[39m\u001b[39m'\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'detlistlist' is not defined"]}],"source":["mudt_translit = translit_dataset(mudt)\n","len(mudt_translit),len(mudt_translit),len(mudt_translit)/len(mudt_translit['word_raw'].unique())\n","mapa_translit = translit_dataset(mapa)\n","len(mapa_translit),len(mapa_translit),len(mapa_translit)/len(mapa_translit['word_raw'].unique())\n","mlrs_translit = translit_dataset(mlrs)\n","len(mlrs_translit),len(mlrs_translit),len(mlrs_translit)/len(mlrs_translit['word_raw'].unique())\n","sa_translit = translit_dataset(sa)\n","len(sa_translit),len(sa_translit),len(sa_translit)/len(sa_translit['word_raw'].unique())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mudt_translit.to_csv('transliterations/mudt_transliterated_tuples.tsv',sep='\\t',index=False)\n","mapa_translit.to_csv('transliterations/mapa_transliterated_tuples.tsv',sep='\\t',index=False)\n","mlrs_translit.to_csv('transliterations/mlrs_transliterated_tuples.tsv',sep='\\t',index=False)\n","sa_translit.to_csv('transliterations/sa_transliterated_tuples.tsv',sep='\\t',index=False)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>freq</th>\n","      <th>word_raw</th>\n","      <th>word_lowered</th>\n","      <th>translit</th>\n","      <th>deterministic</th>\n","      <th>small_cc</th>\n","      <th>augmented_cc</th>\n","      <th>translit_stripped</th>\n","      <th>wordmodel_score</th>\n","      <th>charmodel_score</th>\n","      <th>capitalized</th>\n","      <th>in_langmodel</th>\n","      <th>subtokens</th>\n","      <th>subtokens_lowest_ties</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1268</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>.</td>\n","      <td>-3.556239</td>\n","      <td>-5.553323</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>640</td>\n","      <td>li</td>\n","      <td>li</td>\n","      <td>اللي</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>اللي</td>\n","      <td>اللي</td>\n","      <td>-4.311847</td>\n","      <td>-5.119282</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>640</td>\n","      <td>li</td>\n","      <td>li</td>\n","      <td>لي</td>\n","      <td>NaN</td>\n","      <td>لي</td>\n","      <td>NaN</td>\n","      <td>لي</td>\n","      <td>-4.859493</td>\n","      <td>-5.063514</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>640</td>\n","      <td>li</td>\n","      <td>li</td>\n","      <td>ل</td>\n","      <td>ل</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>ل</td>\n","      <td>-5.295598</td>\n","      <td>-4.732144</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>598</td>\n","      <td>u</td>\n","      <td>u</td>\n","      <td></td>\n","      <td></td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td></td>\n","      <td>-2.06162</td>\n","      <td>-4.263644</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>132012</th>\n","      <td>1</td>\n","      <td>000</td>\n","      <td>000</td>\n","      <td>000</td>\n","      <td>000</td>\n","      <td>000</td>\n","      <td>000</td>\n","      <td>000</td>\n","      <td>-7.459375</td>\n","      <td>-8.066975</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132013</th>\n","      <td>1</td>\n","      <td>0.84</td>\n","      <td>0.84</td>\n","      <td>0.84</td>\n","      <td>0.84</td>\n","      <td>0.84</td>\n","      <td>0.84</td>\n","      <td>0.84</td>\n","      <td>-8.091814</td>\n","      <td>-15.031449</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132014</th>\n","      <td>1</td>\n","      <td>0.58</td>\n","      <td>0.58</td>\n","      <td>0.58</td>\n","      <td>0.58</td>\n","      <td>0.58</td>\n","      <td>0.58</td>\n","      <td>0.58</td>\n","      <td>-8.091814</td>\n","      <td>-14.936831</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132015</th>\n","      <td>1</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>0.01</td>\n","      <td>-8.091814</td>\n","      <td>-14.974067</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>3</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132016</th>\n","      <td>1</td>\n","      <td>&amp;</td>\n","      <td>&amp;</td>\n","      <td>&amp;</td>\n","      <td>&amp;</td>\n","      <td>&amp;</td>\n","      <td>&amp;</td>\n","      <td>&amp;</td>\n","      <td>-7.604577</td>\n","      <td>-6.650987</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>132017 rows × 14 columns</p>\n","</div>"],"text/plain":["        freq word_raw word_lowered translit deterministic small_cc   \n","0       1268        .            .        .             .        .  \\\n","1        640       li           li     اللي           NaN      NaN   \n","2        640       li           li       لي           NaN       لي   \n","3        640       li           li        ل             ل      NaN   \n","4        598        u            u                             NaN   \n","...      ...      ...          ...      ...           ...      ...   \n","132012     1      000          000      000           000      000   \n","132013     1     0.84         0.84     0.84          0.84     0.84   \n","132014     1     0.58         0.58     0.58          0.58     0.58   \n","132015     1     0.01         0.01     0.01          0.01     0.01   \n","132016     1        &            &        &             &        &   \n","\n","       augmented_cc translit_stripped wordmodel_score charmodel_score   \n","0                 .                 .       -3.556239       -5.553323  \\\n","1              اللي              اللي       -4.311847       -5.119282   \n","2               NaN                لي       -4.859493       -5.063514   \n","3               NaN                 ل       -5.295598       -4.732144   \n","4               NaN                          -2.06162       -4.263644   \n","...             ...               ...             ...             ...   \n","132012          000               000       -7.459375       -8.066975   \n","132013         0.84              0.84       -8.091814      -15.031449   \n","132014         0.58              0.58       -8.091814      -14.936831   \n","132015         0.01              0.01       -8.091814      -14.974067   \n","132016            &                 &       -7.604577       -6.650987   \n","\n","        capitalized in_langmodel subtokens  subtokens_lowest_ties  \n","0             False         True         1                      1  \n","1             False         True         1                      1  \n","2             False         True         1                      1  \n","3             False         True         1                      1  \n","4             False         True         0                      1  \n","...             ...          ...       ...                    ...  \n","132012        False         True         1                      1  \n","132013        False        False         3                      1  \n","132014        False        False         3                      1  \n","132015        False        False         3                      1  \n","132016        False         True         1                      1  \n","\n","[132017 rows x 14 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["sa_translit"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"maltifst","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
