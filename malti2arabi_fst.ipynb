{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15725,"status":"ok","timestamp":1680947155928,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"zTPm67tFHXYB","outputId":"2be2bbdb-6f14-4a4d-ab90-5440400781cc"},"outputs":[],"source":["# !git clone https://github.com/fadhleryani/malti_arabi_fst.git\n","# # !git pull\n","\n","# %pip install pynini\n","# %pip install pyfoma"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1680772861174,"user":{"displayName":"Fadhl Eryani","userId":"06943952008454701685"},"user_tz":-60},"id":"MgN2ht6q3QAH","outputId":"0a90890b-21b8-4e93-a193-3bc2306d3dc8"},"outputs":[],"source":["# %cd malti_arabi_fst"]},{"cell_type":"code","execution_count":109,"metadata":{"id":"dn2vYkczBeMZ"},"outputs":[],"source":["import pynini as pn\n","import kenlm\n","from itertools import product\n","import pyconll\n","import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/aggregated_country/lm/word/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n","Loading the LM will be faster if you build a binary file.\n","Reading /Users/f/ba3sasah/malti_arabi_fst/aggregated_country/lm/char/tn-maghreb.arpa\n","----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n","****************************************************************************************************\n"]}],"source":["wordmodel = kenlm.Model('aggregated_country/lm/word/tn-maghreb.arpa')\n","charmodel = kenlm.Model('aggregated_country/lm/char/tn-maghreb.arpa')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["mudt # of sents 2074\n","# of words 12374\n","# of chars 74\n"]}],"source":["dev = pyconll.load_from_file('mt_mudt-ud/mt_mudt-ud-dev.conllu')\n","train = pyconll.load_from_file('mt_mudt-ud/mt_mudt-ud-train.conllu')\n","test = pyconll.load_from_file('mt_mudt-ud/mt_mudt-ud-test.conllu')\n","\n","mudt = dev._sentences + train._sentences + test._sentences\n","\n","print('mudt # of sents',len(mudt))\n","\n","keys = [\"id\",\"form\",\"lemma\",\"upos\",\"xpos\",\"feats\",\"head\",\"deprel\",\"deps\",\"misc\"]\n","\n","sents = []\n","for sent in mudt:\n","    toks = [pd.Series({'sent_id':sent.id,'sent':sent.text})]\n","    # toks = []\n","    for tok in sent:\n","        tokdict = {'sent_id':sent.id}\n","        tokdict.update( {k:tok.__getattribute__(k) for k in keys})\n","        toks.append (pd.Series(tokdict))\n","\n","    sents.append(pd.DataFrame(toks))\n","\n","df = pd.concat(sents)\n","\n","# word_hist\n","word_hist = df['sent'].dropna().str.split().explode().value_counts().reset_index()\n","# word_hist.to_clipboard()\n","print('# of words',len(word_hist))\n","# char hist\n","char_hist = pd.DataFrame([y for x in df['sent'].dropna().str.split().explode().str.casefold().unique() for y in x]).value_counts()\n","# char_hist.to_clipboard()\n","print('# of chars',len(char_hist))\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["closedclass = pd.read_csv('closed_class_mappings.tsv',sep='\\t',header=None) # already unique \n","closedclass = dict(closedclass.values)\n","\n"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["malti2arabi = pn.string_file('malti2arabi.map')\n","\n","malti_sigma = pn.project(malti2arabi,'input')\n","arabi_sigma = pn.project(malti2arabi,'output') \n","\n","sigma_input = pn.union(malti_sigma ).closure()\n","\n","transcriber = pn.union(malti2arabi ).closure()\n","\n","dediac_cross = pn.string_file('dediac.map')\n","\n","diacs = 'ًٌٍَُِّْ'\n","dediac = pn.cdrewrite(dediac_cross,'','',pn.union(arabi_sigma,*diacs).closure())\n","\n","words = pn.string_file('tn-maghreb-words.txt').optimize() @ dediac\n","closedclass_fst = pn.string_file('closed_class_mappings.tsv').optimize()"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["def dediac_fst(text):\n","    try:\n","        return (text @ dediac).string()\n","    except:\n","        return np.nan\n","    \n","words_df= pd.read_fwf('tn-maghreb-words.txt',header=None).rename(columns={0:'words'})\n","words_df['dediac'] = pd.Series([dediac_fst(x) for x in words_df['words']])\n","\n","# words_df"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"data":{"text/plain":["{'original_word': 's',\n"," 'translit': ['س', 'ص'],\n"," 'word': 's',\n"," 'merged': ['س', 'ص'],\n"," 'wordmodel_score': [-6.250324249267578, -7.491082191467285],\n"," 'charmodel_score': [-4.828889846801758, -5.109378337860107],\n"," 'capitalized': False,\n"," 'in_langmodel': [True, True],\n"," 'closed_class': '#na',\n"," 'subtokens': [1, 1],\n"," 'subtokens_lowest_ties': 2}"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["\n","def get_paths(fst,words_only=False):\n","    paths = list(fst.paths().items())\n","    if words_only:\n","        return [x[1] for x in paths]\n","    else:\n","        return paths\n","    \n","def translit_fst(tok):    \n","    fst = (f'<BOS>{tok}<EOS>')  @ transcriber  \n","    # fst = (f'<BOS>{tok}<EOS>')  @ transcriber @ dediac \n","    return fst\n","\n","def remove_plus(text):\n","    return text.replace('+ ','')\n","    # return (text @ pn.cdrewrite(pn.cross('+'+pn.accep(' ').ques,''),'','',arabi_sigma.closure(),direction='rtl')).string() # takes a long time\n","\n","def filter_edge_diacritics(options):\n","    return [y for y in options if y[0] not in diacs and y[-1] not in diacs]\n","\n","\n","def translit_closed_class(word):\n","    outvalue = []\n","    lowered = word.lower()\n","    for tok in lowered.split(): \n","        outvalue.append(closedclass.get(tok,'#na'))\n","\n","    return ' '.join(outvalue)\n","\n","def translit_word(lowered,cutoff=3,useclosedclass=False): #select on merged but return unmerged\n","    lattice = []\n","     # iterate on lower cased\n","    for tok in lowered.replace('-','- ').replace(\"'\",\"' \").split():\n","        if useclosedclass :\n","            cc = closedclass.get(tok)\n","            if cc:\n","                lattice.append([cc])\n","                continue\n","        try:\n","            tok_fst = translit_fst(tok)\n","            translit_toks = get_paths(tok_fst,words_only=True) \n","        except:\n","            lattice.append(['#NA'])\n","            print('fst error',tok,lowered)\n","            continue\n","        if not translit_toks:\n","            lattice.append(['#NA'])            \n","            continue\n","        try:\n","            translit_toks = filter_edge_diacritics(translit_toks) \n","        except:\n","            print('err filtering diacs',translit_toks,tok,lowered)\n","        translit_toks = [(x @ dediac).string() for x in translit_toks]  # dediacritize\n","        lattice.append(translit_toks)\n","    \n","    return [' '.join(x) for x in product(*lattice)]\n","\n","langmodelset =  set(words_df['dediac'])\n","def is_in_lang_model(text):\n","    matches = []\n","    for tok in text.split():\n","        matches.append(tok in langmodelset)\n","    return all(matches)\n","\n","def count_subtokens(text, tokenizer):\n","    return tokenizer(text, add_special_tokens=False, return_length=True)[\"length\"]\n","\n","\n","def translit_and_rank_options(word,useclosedclass=False,cutoff=None):\n","    lowered = word.lower()\n","    translit = translit_word(lowered,useclosedclass=useclosedclass)\n","    if not translit:\n","        translit = [['']]\n","    df = {'original_word':word,'translit':translit}\n","    df['word'] = lowered.replace('-','- ').replace(\"'\",\"' \")\n","    df['merged'] = [x.replace('+ ','') for x in df['translit']]\n","    df['wordmodel_score'] = [wordmodel.score(x) for x in df['merged']]\n","    df['charmodel_score'] = [charmodel.score(' '.join(x)) for x in df['merged'] ]\n","    df['capitalized'] = word[0].isupper() # TODO: what about letter after sink as in 'L-Innu', does it matter?\n","    df['in_langmodel'] = [is_in_lang_model(x) for x in df['merged']] # if all tokens are in lang model\n","    df['closed_class'] = translit_closed_class(df['word'])\n","    df['subtokens'] = count_subtokens(df['merged'], tokenizer)\n","    df['subtokens_lowest_ties'] = sum(np.array(df['subtokens']) == max(df['subtokens']))\n","\n","    \n","    if useclosedclass:\n","        df['translit_cc'] = df.pop('translit')\n","    \n","    if cutoff:\n","        return df.drop_duplicates('merged').sort_values('charmodel_score',ascending=False)[:cutoff]    \n","    return df\n","    \n","\n","word = \"t'\"\n","word = \"uffiċjali\"\n","word = \"L-Innu\"\n","word = \"din\"\n","word = \"f'dik\"\n","word = \"d-dinja\"\n","word = \"f'dil-konferenza d-dinja\"\n","word = \"d-dinja\"\n","word = \"mil-dinja\" # check how many tokens it breaks into and how that affects lang model scores\n","word = \"m'għandhomx\" \n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['charmodel_score'],ascending=False)\n","# translit_and_rank_options(word,cutoff=None,useclosedclass=False).merge(translit_and_rank_options(word,cutoff=None,useclosedclass=True),how='outer').sort_values(['wordmodel_score'],ascending=False)\n","# sorted([(wordmodel.score(x),x) for x in merged],key=lambda x: -x[0])\n","d = translit_and_rank_options(word,cutoff=None,useclosedclass=False)\n","# pd.DataFrame(data=d,index=range(max([len(x) for x in d.values()])))\n","translit_and_rank_options(\"simboli!\")\n","translit_and_rank_options(\"s\")\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# tuple(original_word,\n","# boolean(capitalized or not),\n","# closed class mapping or nill    ,\n","# boolean(Exists or not),\n","# wordmodel score,\n","# charactermodel score,\n","# kurts fertility)\n","\n","# ADD\n","# freq counts (including capitalized and ignoring)\n","# merge and uniq all sets\n","\n","# do example with dik id-dinja / fil- dinja\n","# think about redoing closed class to avoid changing number of tokens\n","\n","# keep track if length of input is same as output (number of tokens)\n","\n","# assume tokenized data (like mudt tokens)?"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fst error \"[sor \"[sor\n","fst error gertrude] gertrude]\n","fst error \\rin[. \\rin[.\n"]}],"source":["# word_hist = word_hist\n","# mudtdev_translit = pd.concat(word_hist['sent'].iloc[:].apply(translit_and_rank_options).values)\n","words_translit = []\n","for word,freq in word_hist.values[:]:\n","    options = translit_and_rank_options(word,useclosedclass=False)\n","    options.update({'freq':freq})\n","    words_translit.append(options)\n","\n","mudt_translit = pd.DataFrame(words_translit)\n"]},{"cell_type":"code","execution_count":118,"metadata":{},"outputs":[],"source":["mudt_translit_exploded = mudt_translit.explode(['translit','merged','wordmodel_score','charmodel_score','in_langmodel','subtokens']).drop_duplicates('translit')"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["mudt_translit_exploded.to_csv('mudt_transliterated_tuples.tsv',sep='\\t')"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["char_hist.to_clipboard()"]},{"cell_type":"code","execution_count":423,"metadata":{},"outputs":[],"source":["def translit_sent(sent):\n","    lattice = []\n","    for word in sent.split():\n","        optionsdf = translit_and_rank_options(word)\n","        options = optionsdf['merged'].values\n","        lattice.append(options)\n","\n","    return list([' '.join(x) for x in product(*lattice)])\n","        \n","def score_generated_sentences(sentences):\n","    return sorted([(x,model.score(x)) for x in sentences],key=lambda y: -y[1])\n","\n","\n","# score_generated_sentences(translit_sentence('malta magħrufa uffiċjalment bħala',cutoff=1))\n","\n","sentout = translit_sent(\"kien bilqiegħda f'dik il-parti\")"]},{"cell_type":"code","execution_count":424,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sent</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>كان بلقعدة في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>كان بلقاعدة في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>كان بلقعده في ديك البارتي</td>\n","      <td>-23.318352</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>كان بلقعدة في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>كان بلقاعدة في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>كان بلقعده في ديك البرتي</td>\n","      <td>-23.817825</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>كان بلقعدة في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>كان بلقاعدة في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>كان بلقعده في ديك البرطي</td>\n","      <td>-23.861692</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                         sent      score\n","0   كان بلقعدة في ديك البارتي -23.318352\n","3  كان بلقاعدة في ديك البارتي -23.318352\n","6   كان بلقعده في ديك البارتي -23.318352\n","1    كان بلقعدة في ديك البرتي -23.817825\n","4   كان بلقاعدة في ديك البرتي -23.817825\n","7    كان بلقعده في ديك البرتي -23.817825\n","2    كان بلقعدة في ديك البرطي -23.861692\n","5   كان بلقاعدة في ديك البرطي -23.861692\n","8    كان بلقعده في ديك البرطي -23.861692"]},"execution_count":424,"metadata":{},"output_type":"execute_result"}],"source":["dfsentout = pd.DataFrame({'sent':sentout})\n","dfsentout['score'] = dfsentout['sent'].apply(wordmodel.score)\n","dfsentout.sort_values('score',ascending=False)"]},{"cell_type":"code","execution_count":535,"metadata":{},"outputs":[],"source":["import numpy as np\n","from transformers import AutoTokenizer\n","\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"CAMeL-Lab/bert-base-arabic-camelbert-mix\")\n","\n","\n","def get_number_of_tokens(token_candidates, tokenizer):\n","    if len(token_candidates) == 0:\n","        print(\"No candidates given!\")\n","        return None\n","\n","    encoded = tokenizer(token_candidates, add_special_tokens=False, return_length=True)\n","    return encoded['len']\n","    token_candidates = np.array(token_candidates)\n","\n","    # np.argmin(encoded[\"length\"])\n","    fewest_splits = min(encoded[\"length\"])\n","    shortest = list(set(token_candidates[np.where(encoded[\"length\"] == min(encoded[\"length\"]))]))\n","    if len(shortest) > 1:\n","        print(f\"Choosing a candidate randomly from {shortest}\")\n","    return shortest[0]\n","\n"]},{"cell_type":"code","execution_count":536,"metadata":{},"outputs":[],"source":["\n","token_candidates = get_paths(translit_fst(\"malta\"))\n","token_candidates = list(map(lambda x: x[1], token_candidates))\n","# token_candidates"]},{"cell_type":"code","execution_count":539,"metadata":{},"outputs":[{"data":{"text/plain":["[('مالتا', 2),\n"," ('مالتَ', 1),\n"," ('مالتا', 2),\n"," ('مالتة', 2),\n"," ('مالته', 2),\n"," ('مالتى', 2),\n"," ('مالطا', 1),\n"," ('مالطَ', 1),\n"," ('مالطا', 1),\n"," ('مالطة', 2),\n"," ('مالطه', 2),\n"," ('مالطى', 2),\n"," ('مَلتا', 1),\n"," ('مَلتَ', 1),\n"," ('مَلتا', 1),\n"," ('مَلتة', 1),\n"," ('مَلته', 1),\n"," ('مَلتى', 1),\n"," ('مَلطا', 1),\n"," ('مَلطَ', 1),\n"," ('مَلطا', 1),\n"," ('مَلطة', 1),\n"," ('مَلطه', 1),\n"," ('مَلطى', 1)]"]},"execution_count":539,"metadata":{},"output_type":"execute_result"}],"source":["list(zip(token_candidates,get_number_of_tokens(token_candidates,tokenizer)['length']))"]},{"cell_type":"code","execution_count":534,"metadata":{},"outputs":[{"data":{"text/plain":["['مالتا',\n"," 'مالتَ',\n"," 'مالتا',\n"," 'مالتة',\n"," 'مالته',\n"," 'مالتى',\n"," 'مالطا',\n"," 'مالطَ',\n"," 'مالطا',\n"," 'مالطة',\n"," 'مالطه',\n"," 'مالطى',\n"," 'مَلتا',\n"," 'مَلتَ',\n"," 'مَلتا',\n"," 'مَلتة',\n"," 'مَلته',\n"," 'مَلتى',\n"," 'مَلطا',\n"," 'مَلطَ',\n"," 'مَلطا',\n"," 'مَلطة',\n"," 'مَلطه',\n"," 'مَلطى']"]},"execution_count":534,"metadata":{},"output_type":"execute_result"}],"source":["token_candidates"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"maltifst","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
